<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[The C++ scientist]]></title>
  <link href="http://jmabille.github.io/atom.xml" rel="self"/>
  <link href="http://jmabille.github.io/"/>
  <updated>2015-04-27T09:18:23+02:00</updated>
  <id>http://jmabille.github.io/</id>
  <author>
    <name><![CDATA[Johan Mabille]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Aligned Memory Allocator]]></title>
    <link href="http://jmabille.github.io/blog/2014/12/06/aligned-memory-allocator/"/>
    <updated>2014-12-06T08:59:40+01:00</updated>
    <id>http://jmabille.github.io/blog/2014/12/06/aligned-memory-allocator</id>
    <content type="html"><![CDATA[<h2 id="introduction">Introduction</h2>

<p>In a previous <a href="http://jmabille.github.io/blog/2014/10/13/writing-c-plus-plus-wrappers-for-simd-intrinsics-4/#simd_memory_allocator">article about SIMD wrappers</a>, I suggested to design a dedicated memory allocator to handle SIMD memory alignment constraints, but I didn’t give
any details on how to do it. That’s the purpose of this article. The C++ standard describes a set of requirements our allocator must respect
so it can work with standard containers. After a survey of these standard requirements, we’ll see how to implement an aligned memory allocator
that meets them.</p>

<!-- more -->

<h2 id="the-c-standard-requirements">1. The C++ standard requirements</h2>

<p>The standard requires the allocator to define the following type:</p>

<ul>
  <li><strong>value_type</strong>: the type of allocated elements, T</li>
  <li><strong>pointer</strong> and <strong>const_pointer</strong>: pointer and constant pointer to T</li>
  <li><strong>reference</strong> and <strong>constant_reference</strong>: reference and constant reference to T</li>
  <li><strong>size_type</strong>: an unsigned integral type that can represent the size of the largest object in the allocation model</li>
  <li><strong>difference_type</strong>: a signed integral type that can represent the difference between any two pointers in the allocation model</li>
</ul>

<p>The standard then requires a template class <strong>rebind</strong> member, which is a template typedef: Allocator&lt;T&gt;::rebind&lt;U&gt;::other is the same type as
Allocator&lt;U&gt;. This member is used by container that allocates memory for internal structures that hold T elements instead of allocating memory
for T elements. For instance, std::list&lt;T&gt; allocates memory for Node&lt;T&gt; instead of T, but you don’t want to use Allocator&lt;Node&lt;T&gt; &gt; as
template parameter since this would expose implementation details in the interface. Thus you use Allocator&lt;T&gt; and the internal allocation
is done with Allocator&lt;T&gt;::rebind&lt;U&gt;::other.allocate(n).</p>

<p>Then we have to provide the <strong>address</strong> functions, which return the address of a given object. Two overloads are provided, one for references
and one for constant references.</p>

<p>The two following functions are the essential part of the allocator: <strong>allocate</strong> and <strong>deallocate</strong>, which allocates/deallocates memory for
n objects of type T. These functions are low level memory management functions and are not responsible for constructing or destroying objects,
this has to be done in specific functions: <strong>construct</strong> and <strong>destroy</strong>.</p>

<p>The last specific function is <strong>max_size</strong>, a function that returns the maximum value that can be passed to allocate.</p>

<p>Finally, the allocator must provide default and copy constructors, and equality check operators.</p>

<h2 id="aligned-memory-allocator-interface">2. Aligned memory allocator interface</h2>

<p>Since we must handle different memory alignment bound, our aligned memory allocator will take two template parameters: <strong>T</strong>, the type of allocated
objects, and <strong>N</strong>, the aligment bound. Given the requirements of the previous section, the allocator interface looks like:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>aligned_allocator.hpp </span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
<a href="#n7" name="n7">7</a>
<a href="#n8" name="n8">8</a>
<a href="#n9" name="n9">9</a>
<strong><a href="#n10" name="n10">10</a></strong>
<a href="#n11" name="n11">11</a>
<a href="#n12" name="n12">12</a>
<a href="#n13" name="n13">13</a>
<a href="#n14" name="n14">14</a>
<a href="#n15" name="n15">15</a>
<a href="#n16" name="n16">16</a>
<a href="#n17" name="n17">17</a>
<a href="#n18" name="n18">18</a>
<a href="#n19" name="n19">19</a>
<strong><a href="#n20" name="n20">20</a></strong>
<a href="#n21" name="n21">21</a>
<a href="#n22" name="n22">22</a>
<a href="#n23" name="n23">23</a>
<a href="#n24" name="n24">24</a>
<a href="#n25" name="n25">25</a>
<a href="#n26" name="n26">26</a>
<a href="#n27" name="n27">27</a>
<a href="#n28" name="n28">28</a>
<a href="#n29" name="n29">29</a>
<strong><a href="#n30" name="n30">30</a></strong>
<a href="#n31" name="n31">31</a>
<a href="#n32" name="n32">32</a>
<a href="#n33" name="n33">33</a>
<a href="#n34" name="n34">34</a>
<a href="#n35" name="n35">35</a>
<a href="#n36" name="n36">36</a>
<a href="#n37" name="n37">37</a>
<a href="#n38" name="n38">38</a>
<a href="#n39" name="n39">39</a>
<strong><a href="#n40" name="n40">40</a></strong>
<a href="#n41" name="n41">41</a>
<a href="#n42" name="n42">42</a>
<a href="#n43" name="n43">43</a>
</pre></td>
  <td class="code"><pre>
<span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="class">T</span>, <span class="predefined-type">int</span> N&gt;
    <span class="keyword">class</span> <span class="class">aligned_allocator</span>
    {

    <span class="directive">public</span>:

        <span class="keyword">typedef</span> T value_type;
        <span class="keyword">typedef</span> T&amp; reference;
        <span class="keyword">typedef</span> <span class="directive">const</span> T&amp; const_reference;
        <span class="keyword">typedef</span> T* pointer;
        <span class="keyword">typedef</span> <span class="directive">const</span> T* const_pointer;
        <span class="keyword">typedef</span> size_t size_type;
        <span class="keyword">typedef</span> ptrdiff_t difference_type;

        <span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="class">U</span>&gt;
            <span class="keyword">struct</span> rebind
            {
                <span class="keyword">typedef</span> aligned_allocator&lt;U,N&gt; other;
            };

        <span class="directive">inline</span> aligned_allocator() <span class="keyword">throw</span>() {}
        <span class="directive">inline</span> aligned_allocator(<span class="directive">const</span> aligned_allocator&amp;) <span class="keyword">throw</span>() {}

        <span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="class">U</span>&gt;
            <span class="directive">inline</span> aligned_allocator(<span class="directive">const</span> aligned_allocator&lt;U,N&gt;&amp;) <span class="keyword">throw</span>() {}

        <span class="directive">inline</span> ~aligned_allocator() <span class="keyword">throw</span>() {}

        <span class="directive">inline</span> pointer address(reference r) { <span class="keyword">return</span> &amp;r; }
        <span class="directive">inline</span> const_pointer address(const_reference r) <span class="directive">const</span> { <span class="keyword">return</span> &amp;r; }

        pointer allocate(size_type n, <span class="keyword">typename</span> std::allocator&lt;<span class="directive">void</span>&gt;::const_pointer hint = <span class="integer">0</span>);
        <span class="directive">inline</span> <span class="directive">void</span> deallocate(pointer p, size_type);

        <span class="directive">inline</span> <span class="directive">void</span> construct(pointer p, const_reference value) { <span class="keyword">new</span> (p) value_type(value); }
        <span class="directive">inline</span> <span class="directive">void</span> destroy(pointer p) { p-&gt;~value_type(); }

        <span class="directive">inline</span> size_type max_size() <span class="directive">const</span> <span class="keyword">throw</span>() { <span class="keyword">return</span> size_type(-<span class="integer">1</span>) / <span class="keyword">sizeof</span>(T); }

        <span class="directive">inline</span> <span class="predefined-type">bool</span> <span class="directive">operator</span>==(<span class="directive">const</span> aligned_allocator&amp;) { <span class="keyword">return</span> <span class="predefined-constant">true</span>; }
        <span class="directive">inline</span> <span class="predefined-type">bool</span> <span class="directive">operator</span>!=(<span class="directive">const</span> aligned_allocator&amp; rhs) { <span class="keyword">return</span> !<span class="directive">operator</span>==(rhs); }
    };
</pre></td>
</tr></table>
 </figure></notextile></div>

<p>Nothing special to say here, the <strong>construct</strong> function calls the copy constructor of T through the placement new operator but does not allocate memory for
the element, this is the responsibility of the <strong>allocate</strong> function. Same thing for the <strong>destroy</strong> function, it calls the destructor of T but it doesn’t deallocate memory, this has to be done after with a call to the <strong>deallocate</strong> function.</p>

<h2 id="allocate-and-deallocate-implementation">3. Allocate and deallocate implementation</h2>

<p>We can now focus on the <strong>allocate</strong> and <strong>deallocate</strong> implementation. Depending on our platform, aligned memory allocation function may be available:</p>

<ul>
  <li>On Windows 64 bits, FreeBSD (except on ARM and MIPS architectures), and Apple, the <strong>malloc</strong> function is already 16-bytes aligned</li>
  <li>Systems implementing POSIX provide the <strong>posix_memalign</strong> function</li>
  <li>SSE intrinsics provide the <strong>_mm_malloc</strong> function</li>
  <li>Visual Studio provides the <strong>_aligned_malloc</strong> function</li>
</ul>

<p>Except for the 16-bytes aligned malloc, every function takes an alignment parameter that must be a power of 2, thus the <strong>N</strong> template parameter of our allocator should be a power of 2 so it can works with these aligned memory allocation functions. Note that many of these functions can be available on a same platform.</p>

<p>Assume we can detect at compile time if such functions are available (we’ll come back on this later); we can provide a function that
selects the aligned memory allocation to use if such a function is available, otherwise forwards to our own implementation:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>aligned_allocator.hpp </span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
<a href="#n7" name="n7">7</a>
<a href="#n8" name="n8">8</a>
<a href="#n9" name="n9">9</a>
<strong><a href="#n10" name="n10">10</a></strong>
<a href="#n11" name="n11">11</a>
<a href="#n12" name="n12">12</a>
<a href="#n13" name="n13">13</a>
<a href="#n14" name="n14">14</a>
<a href="#n15" name="n15">15</a>
<a href="#n16" name="n16">16</a>
<a href="#n17" name="n17">17</a>
<a href="#n18" name="n18">18</a>
<a href="#n19" name="n19">19</a>
<strong><a href="#n20" name="n20">20</a></strong>
<a href="#n21" name="n21">21</a>
<a href="#n22" name="n22">22</a>
<a href="#n23" name="n23">23</a>
<a href="#n24" name="n24">24</a>
<a href="#n25" name="n25">25</a>
<a href="#n26" name="n26">26</a>
<a href="#n27" name="n27">27</a>
<a href="#n28" name="n28">28</a>
<a href="#n29" name="n29">29</a>
<strong><a href="#n30" name="n30">30</a></strong>
<a href="#n31" name="n31">31</a>
<a href="#n32" name="n32">32</a>
<a href="#n33" name="n33">33</a>
</pre></td>
  <td class="code"><pre>
<span class="keyword">namespace</span> detail
{
    <span class="directive">inline</span> <span class="directive">void</span>* _aligned_malloc(size_t size, size_t alignment)
    {
        <span class="directive">void</span>* res = <span class="integer">0</span>;
        <span class="directive">void</span>* ptr = malloc(size+alignment);
        <span class="keyword">if</span>(ptr != <span class="integer">0</span>)
        {
            res = <span class="keyword">reinterpret_cast</span>&lt;<span class="directive">void</span>*&gt;((<span class="keyword">reinterpret_cast</span>&lt;size_t&gt;(ptr) &amp; ~(size_t(alignment-<span class="integer">1</span>))) + alignment);
            *(<span class="keyword">reinterpret_cast</span>&lt;<span class="directive">void</span>**&gt;(res) - <span class="integer">1</span>) = ptr;
        }
        <span class="keyword">return</span> res;
    }
}

<span class="directive">inline</span> <span class="directive">void</span>* aligned_malloc(size_t size, size_t alignment)
{
    <span class="preprocessor">#if</span> MALLOC_ALREADY_ALIGNED
        <span class="keyword">return</span> malloc(size);
    <span class="preprocessor">#elif</span> HAS_MM_MALLOC
        <span class="keyword">return</span> _mm_malloc(size,alignment);
    <span class="preprocessor">#elif</span> HAS_POSIX_MEMALIGN
        <span class="directive">void</span>* res;
        <span class="directive">const</span> <span class="predefined-type">int</span> failed = posix_memalign(&amp;res,size,alignment);
        <span class="keyword">if</span>(failed) res = <span class="integer">0</span>;
        <span class="keyword">return</span> res;
    <span class="preprocessor">#elif</span> (defined _MSC_VER)
        <span class="keyword">return</span> _aligned_malloc(size, alignment);
    <span class="preprocessor">#else</span>
        <span class="keyword">return</span> detail::_aligned_malloc(size,alignment);
    <span class="preprocessor">#endif</span>
}
</pre></td>
</tr></table>
 </figure></notextile></div>

<p>The idea in the <strong>_aligned_malloc</strong> function is to search for the first aligned memory address (<em>res</em>) after the one returned by the classic malloc function (<em>ptr</em>), and to use it as return value. But since we must ensure <em>size</em> bytes are available after <em>res</em>, we must allocate more than <em>size</em> bytes; the minimum size to allocate to prevent buffer overflow is <em>size+alignment</em>. The we store the <em>ptr</em> value just before <em>res</em> so the <strong>_aligned_free</strong> function can easily retrieve and pass it to the classic free function:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>aligned_allocator.hpp </span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
<a href="#n7" name="n7">7</a>
<a href="#n8" name="n8">8</a>
<a href="#n9" name="n9">9</a>
<strong><a href="#n10" name="n10">10</a></strong>
<a href="#n11" name="n11">11</a>
<a href="#n12" name="n12">12</a>
<a href="#n13" name="n13">13</a>
<a href="#n14" name="n14">14</a>
<a href="#n15" name="n15">15</a>
<a href="#n16" name="n16">16</a>
<a href="#n17" name="n17">17</a>
<a href="#n18" name="n18">18</a>
<a href="#n19" name="n19">19</a>
<strong><a href="#n20" name="n20">20</a></strong>
<a href="#n21" name="n21">21</a>
<a href="#n22" name="n22">22</a>
<a href="#n23" name="n23">23</a>
<a href="#n24" name="n24">24</a>
</pre></td>
  <td class="code"><pre>
<span class="keyword">namespace</span> detail
{
    <span class="directive">inline</span> <span class="directive">void</span> _aligned_free(<span class="directive">void</span>* ptr)
    {
        <span class="keyword">if</span>(ptr != <span class="integer">0</span>)
            free(*(<span class="keyword">reinterpret_cast</span>&lt;<span class="directive">void</span>**&gt;(ptr)-<span class="integer">1</span>));
    }
}

<span class="directive">inline</span> <span class="directive">void</span> aligned_free(<span class="directive">void</span>* ptr)
{
    <span class="preprocessor">#if</span> MALLOC_ALREADY_ALIGNED
        free(ptr);
    <span class="preprocessor">#elif</span> HAS_MM_MALLOC
        _mm_free(ptr);
    <span class="preprocessor">#elif</span> HAS_POSIX_MEMALIGN
        free(ptr);
    <span class="preprocessor">#elif</span> defined(_MSC_VER)
        _aligned_free(ptr);
    <span class="preprocessor">#else</span>
        detail::_aligned_free(ptr);
    <span class="preprocessor">#endif</span>
    }
</pre></td>
</tr></table>
 </figure></notextile></div>

<p>The <strong>aligned_free</strong> function is the symmetric of <strong>aligned_malloc</strong>: it selects the aligned memory function available or forwards to the <strong>_aligned_free</strong> function.</p>

<p>We can now write the <strong>allocate</strong> and <strong>deallocate</strong> functions of the allocator:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>aligned_allocator.hpp </span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
<a href="#n7" name="n7">7</a>
<a href="#n8" name="n8">8</a>
<a href="#n9" name="n9">9</a>
<strong><a href="#n10" name="n10">10</a></strong>
<a href="#n11" name="n11">11</a>
<a href="#n12" name="n12">12</a>
<a href="#n13" name="n13">13</a>
<a href="#n14" name="n14">14</a>
<a href="#n15" name="n15">15</a>
<a href="#n16" name="n16">16</a>
<a href="#n17" name="n17">17</a>
</pre></td>
  <td class="code"><pre>
<span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="class">T</span>, <span class="predefined-type">int</span> N&gt;
    <span class="keyword">typename</span> aligned_allocator&lt;T,N&gt;::pointer
    aligned_allocator&lt;T,N&gt;::allocate(size_type n, <span class="keyword">typename</span> std::allocator&lt;<span class="directive">void</span>&gt;::const_pointer hint)
    {
        pointer res = <span class="keyword">reinterpret_cast</span>&lt;pointer&gt;(aligned_malloc(<span class="keyword">sizeof</span>(T)*n,N));
        <span class="keyword">if</span>(res == <span class="integer">0</span>)
            <span class="keyword">throw</span> std::bad_alloc();
        <span class="keyword">return</span> res;
    }

<span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="class">T</span>, <span class="predefined-type">int</span> N&gt;
    <span class="keyword">typename</span> aligned_allocator&lt;T,N&gt;::pointer
    aligned_allocator&lt;T,N&gt;::deallocate(pointer p, size_type)
    {
    aligned_free(p);
    }
</pre></td>
</tr></table>
 </figure></notextile></div>

<p>Here we see the advantage to have encapsulated aligned memory allocation selection in a dedicated function: the allocate function of the allocator simply forwards to this dedicated function and then handles possible bad allocation. The result is a code simple and easy to read. Another advantage is you can
use <strong>aligned_malloc</strong> and <strong>aligned_free</strong> functions outside the <strong>aligned_allocator</strong> class if you need.</p>

<p>Note: the call to malloc after the MALLOC_ALREADY_ALIGNED preprocessor token should be available for 16-bytes aligned memory allocator only (the same applies to the call to free). Thus we should provide two versions of <strong>aligned_malloc</strong> and <strong>aligned_free</strong> and a specialization of the allocator ofr
<strong>N = 16</strong>.</p>

<h2 id="detecting-available-aligned-memory-allocation">4. Detecting available aligned memory allocation</h2>

<p>Now that we have implemented the allocation and deallocation methods, we can come back to the preprocessor tokens. Defining these tokens is not simple because you have to refer to the documentation of a lot of various systems and architectures. Thus there’s a chance that we may not be comprehensive, but at least we can cover the most common platforms.</p>

<p>Let’s start with the GNU world; according to this <a href="http://www.gnu.org/s/libc/manual/html_node/Aligned-Memory-Blocks.html">documentation</a>, “The address of a block returned by malloc or realloc in GNU systems is always a multiple of eight (or sixteen on 64-bit systems)”. According to this <a href="http://gcc.fyxm.net/summit/2003/Porting%20to%2064%20bit.pdf">one</a>, page 114, “[The] LP64 model […] is used by all 64-bit UNIX ports”, therefore we should use this predefined macro instead of __x86_64__ (this last one won’t work on PowerPC or SPARC). Thus we can define the following macro:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>aligned_allocator.hpp </span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
<a href="#n7" name="n7">7</a>
</pre></td>
  <td class="code"><pre>
<span class="preprocessor">#if</span> defined(__GLIBC__) &amp;&amp; ((__GLIBC__&gt;=<span class="integer">2</span> &amp;&amp; __GLIBC_MINOR__ &gt;= <span class="integer">8</span>) || __GLIBC__&gt;<span class="integer">2</span>) \
 &amp;&amp; defined(__LP64__)
  <span class="preprocessor">#define</span> GLIBC_MALLOC_ALREADY_ALIGNED <span class="integer">1</span>
<span class="preprocessor">#else</span>
  <span class="preprocessor">#define</span> GLIBC_MALLOC_ALREADY_ALIGNED <span class="integer">0</span>
<span class="preprocessor">#endif</span>
</pre></td>
</tr></table>
 </figure></notextile></div>

<p>FreeBSD has 16-byte aligned malloc, except on ARM and MIPS architectures (see this <a href="ttp://svn.freebsd.org/viewvc/base/stable/7/lib/libc/stdlib/malloc.c?view=markup">documentation</a>):</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>aligned_allocator.hpp </span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
</pre></td>
  <td class="code"><pre>
<span class="preprocessor">#if</span> defined(__FreeBSD__) &amp;&amp; !defined(__arm__) &amp;&amp; !defined(__mips__)
  <span class="preprocessor">#define</span> FREEBSD_MALLOC_ALREADY_ALIGNED <span class="integer">1</span>
<span class="preprocessor">#else</span>
  <span class="preprocessor">#define</span> FREEBSD_MALLOC_ALREADY_ALIGNED <span class="integer">0</span>
<span class="preprocessor">#endif</span>
</pre></td>
</tr></table>
 </figure></notextile></div>

<p>On windows 64 bits and Apple OS, the malloc function is also already aligned, thus we can define the <strong>MALLOC_ALREADY_ALIGNED</strong> macro, based on these information and the macros previously defined:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>aligned_allocator.hpp </span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
<a href="#n7" name="n7">7</a>
<a href="#n8" name="n8">8</a>
<a href="#n9" name="n9">9</a>
</pre></td>
  <td class="code"><pre>
<span class="preprocessor">#if</span> (defined(__APPLE__) \
 || defined(_WIN64) \
 || GLIBC_MALLOC_ALREADY_ALIGNED \
 || FREEBSD_MALLOC_ALREADY_ALIGNED)
  <span class="preprocessor">#define</span> MALLOC_ALREADY_ALIGNED <span class="integer">1</span>
<span class="preprocessor">#else</span>
  <span class="preprocessor">#define</span> MALLOC_ALREADY_ALIGNED <span class="integer">0</span>
<span class="preprocessor">#endif</span>
</pre></td>
</tr></table>
 </figure></notextile></div>

<p>To handle systems implementing POSIX:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>aligned_allocator.hpp </span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
<a href="#n7" name="n7">7</a>
</pre></td>
  <td class="code"><pre>
<span class="preprocessor">#if</span> ((defined __QNXNTO__) || (defined _GNU_SOURCE) || ((defined _XOPEN_SOURCE) &amp;&amp; (_XOPEN_SOURCE &gt;= <span class="integer">600</span>))) \
 &amp;&amp; (defined _POSIX_ADVISORY_INFO) &amp;&amp; (_POSIX_ADVISORY_INFO &gt; <span class="integer">0</span>)
  <span class="preprocessor">#define</span> HAS_POSIX_MEMALIGN <span class="integer">1</span>
<span class="preprocessor">#else</span>
  <span class="preprocessor">#define</span> HAS_POSIX_MEMALIGN <span class="integer">0</span>
<span class="preprocessor">#endif</span>
</pre></td>
</tr></table>
 </figure></notextile></div>

<p>The last macro to define is <strong>HAS_MM_MALLOC</strong>; the _mm_malloc function is provided with SSE intrinsics, thus we can rely on the macros defined in this <a href="http://jmabille.github.io/blog/2014/10/25/writing-c-plus-plus-wrappers-for-simd-intrinsics-5#detecting_instr_set">article</a>:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>aligned_allocator.hpp </span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
</pre></td>
  <td class="code"><pre>
<span class="preprocessor">#if</span> SSE_INSTR_SET &gt; <span class="integer">0</span>
    <span class="preprocessor">#define</span> HAS_MM_MALLOC <span class="integer">1</span>
<span class="preprocessor">#else</span>
    <span class="preprocessor">#define</span> HAS_MM_MALLOC <span class="integer">0</span>
<span class="preprocessor">#endif</span>
</pre></td>
</tr></table>
 </figure></notextile></div>

<p>That’s it, some architectures may be missing but it shouldn’t be too complicated to handle them with appropriate documentation.</p>

<h2 id="conclusion">Conclusion</h2>

<p>The aligned memory allocator designed in this article meets the standard requirements and can therefore be used with any container of the STL. If you work with intrinsics wrappers and std::vector, this allocator will allow you to load the data from memory with the <a href="http://jmabille.github.io/blog/2014/10/25/writing-c-plus-plus-wrappers-for-simd-intrinsics-5#simd_load">load_a</a> method, faster than <a href="http://jmabille.github.io/blog/2014/10/25/writing-c-plus-plus-wrappers-for-simd-intrinsics-5#simd_load">load_u</a> (the same applies for storing data to memory):</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>sample.cpp </span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
<a href="#n7" name="n7">7</a>
<a href="#n8" name="n8">8</a>
<a href="#n9" name="n9">9</a>
<strong><a href="#n10" name="n10">10</a></strong>
<a href="#n11" name="n11">11</a>
</pre></td>
  <td class="code"><pre>
<span class="keyword">typedef</span> std::vector&lt;<span class="predefined-type">double</span>,aligned_allocator&lt;<span class="predefined-type">double</span>,<span class="integer">16</span>&gt; &gt; vector_type;
vector_type v1,v2,v3;
<span class="comment">// code filling v1 and v2</span>
<span class="keyword">for</span>(size_t i = <span class="integer">0</span>; i &lt; v1.size(); i += simd_traits&lt;<span class="predefined-type">double</span>&gt;::size)
{
    vector2d v1d = load_a(&amp;v1[i]);
    vector2d v2d = load_a(&amp;v2[i]);
    vector2d v3d = v1d + v2d;
    store_a(&amp;v3[i],v3d);
}
</pre></td>
</tr></table>
 </figure></notextile></div>

<p>But as we’ll see in a next article, std::vector may not be the more appropriate container for fast computation programs.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Performance Considerations About SIMD Wrappers]]></title>
    <link href="http://jmabille.github.io/blog/2014/11/20/performance-considerations-about-simd-wrappers/"/>
    <updated>2014-11-20T01:39:57+01:00</updated>
    <id>http://jmabille.github.io/blog/2014/11/20/performance-considerations-about-simd-wrappers</id>
    <content type="html"><![CDATA[<p>When I posted a link to this blog on <a href="http://www.reddit.com/r/cpp/comments/2laltn/ths_c_scientist_blog_is_born/">reddit</a>,
I had comments from people who were skeptical of the <a href="http://jmabille.github.io/blog/2014/10/09/writing-c-plus-plus-wrappers-for-simd-intrinsics-1/">SIMD Wrappers</a>
performances. They raised many possible performance hits in the implementation:</p>

<ul>
  <li>Arguments passed by const references instead of values, introducing a useless indirection and preventing the compiler from
keeping the variable into registers</li>
  <li>Indirection due to the wrapping of __mXXX types into objects</li>
  <li>Operator overloads preventing the compiler from proper instruction reordering during optimization</li>
</ul>

<!-- more -->

<p>I’ve always thought the compiler was smart enough to handle registers and optimizations, whatever the type of the functions arguments (const
references or values); and I don’t understand why operators overloads shouldn’t be considered as classical functions by the compiler. But well,
maybe I am too optimistic about the capabilities of the compiler? I was suggested a solution based on pure functions that should be simpler
and faster, but I was not given any evidence. Let’s take a closer look at both implementations and the assembly code they generate so we can say
whether or not the wrappers introduce performance hits.</p>

<p>Before we go further, here are some technical details: the compiler used in this article is gcc 4.7.3, results may be different with another compiler
(and I am interested in seeing these results). The SIMD wrappers used are those of the article series mentioned above, and the implementation based
on stateless pure functions looks like:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>simd_function.hpp </span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
<a href="#n7" name="n7">7</a>
<a href="#n8" name="n8">8</a>
<a href="#n9" name="n9">9</a>
<strong><a href="#n10" name="n10">10</a></strong>
<a href="#n11" name="n11">11</a>
<a href="#n12" name="n12">12</a>
<a href="#n13" name="n13">13</a>
<a href="#n14" name="n14">14</a>
<a href="#n15" name="n15">15</a>
<a href="#n16" name="n16">16</a>
<a href="#n17" name="n17">17</a>
<a href="#n18" name="n18">18</a>
<a href="#n19" name="n19">19</a>
<strong><a href="#n20" name="n20">20</a></strong>
<a href="#n21" name="n21">21</a>
<a href="#n22" name="n22">22</a>
</pre></td>
  <td class="code"><pre>
<span class="keyword">typedef</span> __m128 vector4f2;

<span class="directive">inline</span> vector4f2 add(vector4f2 lhs, vector4f2 rhs)
{
    <span class="keyword">return</span> _mm_add_ps(lhs,rhs);
}

<span class="directive">inline</span> vector4f mul(vector4f2 lhs, vector4f2 rhs)
{
    <span class="keyword">return</span> _mm_mul_ps(lhs,rhs);
}

<span class="directive">inline</span> vector4f2 load_a(<span class="directive">const</span> <span class="predefined-type">float</span>* src)
{
    <span class="keyword">return</span> _mm_load_ps(src);
}

<span class="directive">inline</span> vector4f2 store_a(<span class="predefined-type">float</span>* dst, vector4f2 src)
{
    _mm_store_ps(dst,src);
}
</pre></td>
</tr></table>
 </figure></notextile></div>

<h2 id="pure-function-vs-simd-wrappers">1. Pure function vs SIMD wrappers</h2>

<p>Let’s see the assembly code generated by the following functions:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>simd_test.cpp </span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
<a href="#n7" name="n7">7</a>
<a href="#n8" name="n8">8</a>
<a href="#n9" name="n9">9</a>
<strong><a href="#n10" name="n10">10</a></strong>
<a href="#n11" name="n11">11</a>
</pre></td>
  <td class="code"><pre>
vector4f test_sse_a(vector4f a, vector4f b)
{
    <span class="keyword">return</span> a + b;
}


vector4f2 test_sse_a2(vector4f2 a, vector4f2 b)
{
    <span class="keyword">return</span> add(a,b);
}
</pre></td>
</tr></table>
 </figure></notextile></div>

<p>The generated assembly code is:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>simd_test.asm </span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
<a href="#n7" name="n7">7</a>
<a href="#n8" name="n8">8</a>
<a href="#n9" name="n9">9</a>
<strong><a href="#n10" name="n10">10</a></strong>
<a href="#n11" name="n11">11</a>
<a href="#n12" name="n12">12</a>
</pre></td>
  <td class="code"><pre>
// test_sse_a
   0:    c5 f8 28 06              vmovaps (%rsi),%xmm0
   4:    48 89 f8                 mov    %rdi,%rax
   7:    c5 f8 58 02              vaddps (%rdx),%xmm0,%xmm0
   b:    c5 f8 29 07              vmovaps %xmm0,(%rdi)
   f:    c3                       retq
// test_sse_a2
   0:    c5 f8 58 c1              vaddps %xmm1,%xmm0,%xmm0
   4:    c3                       retq
   5:    66 66 2e 0f 1f 84 00     data32 nopw %cs:0x0(%rax,%rax,1)
   c:    00 00 00 00 
</pre></td>
</tr></table>
 </figure></notextile></div>

<p>If you’re not familiar with assembler, vaddps is the assembly for _mm_add_ps (strictly speaking for _m256_add_ps, but this doesn’t make a 
big difference), vmovaps is a transfer instruction from memory to SIMD register (load) or from SIM register to memory (store) depending on its
arguments, and %xmmX are the SIMD registers. Do not worry about the last line of the test_sse_a2 function, this is a “do-nothing” operation,
used for padding, and does not concern us here.</p>

<p>So what can we tell at first sight ? Well, it seems SIMD wrappers introduce an overhead, using transfer instructions, while the implementation
based on stateless functions directly uses register. Now the question is why. Is this due to constant reference arguments ?</p>

<h2 id="constant-reference-argument-vs-value-argument">2. Constant reference argument vs value argument</h2>

<p>If we change the code of the SIMD wrappers operator overloads to take their arguments by value rather than by constant reference, the generated
assembly code doesn’t change:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>simd_sse.hpp</span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
<a href="#n7" name="n7">7</a>
<a href="#n8" name="n8">8</a>
<a href="#n9" name="n9">9</a>
<strong><a href="#n10" name="n10">10</a></strong>
<a href="#n11" name="n11">11</a>
<a href="#n12" name="n12">12</a>
</pre></td>
  <td class="code"><pre>
<span class="directive">inline</span> vector4f <span class="directive">operator</span>+(vector4f lhs, vector4f rhs)
{
    <span class="keyword">return</span> _mm_add_ps(lhs,rhs);
}

<span class="comment">// test_sse_a asm:</span>
   <span class="integer">0</span>:    c5 f8 <span class="integer">28</span> <span class="octal">06</span>              vmovaps (%rsi),%xmm0
   <span class="integer">4</span>:    <span class="integer">48</span> <span class="integer">89</span> f8                 mov    %rdi,%rax
   <span class="integer">7</span>:    c5 f8 <span class="integer">58</span> <span class="octal">02</span>              vaddps (%rdx),%xmm0,%xmm0
   b:    c5 f8 <span class="integer">29</span> <span class="octal">07</span>              vmovaps %xmm0,(%rdi)
   f:    c3
</pre></td>
</tr></table>
 </figure></notextile></div>

<p>Moreover, if we change the functional implementation so it takes arguments by constant reference instead of value, the generated assembly code for
test_sse_a2 is exactly the same as in the previous section:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>simd_test.cpp </span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
<a href="#n7" name="n7">7</a>
<a href="#n8" name="n8">8</a>
<a href="#n9" name="n9">9</a>
<strong><a href="#n10" name="n10">10</a></strong>
<a href="#n11" name="n11">11</a>
</pre></td>
  <td class="code"><pre>
<span class="directive">inline</span> vector4f2 add(<span class="directive">const</span> vector4f2&amp; lhs, <span class="directive">const</span> vector4f2&amp; rhs)
{
    <span class="keyword">return</span> _mm_add_ps(lhs,rhs);
}

<span class="comment">// test_sse_a2 asm:</span>
   <span class="integer">0</span>:    c5 f8 <span class="integer">58</span> c1              vaddps %xmm1,%xmm0,%xmm0
   <span class="integer">4</span>:    c3                       retq
   <span class="integer">5</span>:    <span class="integer">66</span> <span class="integer">66</span> <span class="float">2</span>e <span class="float">0f</span> <span class="float">1f</span> <span class="integer">84</span> <span class="octal">00</span>     data32 nopw %cs:<span class="hex">0x0</span>(%rax,%rax,<span class="integer">1</span>)
   c:    <span class="octal">00</span> <span class="octal">00</span> <span class="octal">00</span> <span class="octal">00</span> 
</pre></td>
</tr></table>
 </figure></notextile></div>

<p>As I supposed, the compiler (at least gcc) is smart enough to optimize and keep in register arguments passed by constant reference (if they fit into
registers of course). So it seems the overhead comes from the indirection of the wrapping, but this is really hard to believe.</p>

<h2 id="and-the-culprit-is-">3. And the culprit is …</h2>

<p>To confirm this hypothesis, let’s simplify the code of the wrapper so we only test the indirection. Inheritance from the <strong>simd_vector</strong> base class
is removed:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>simd_sse.hpp</span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
<a href="#n7" name="n7">7</a>
<a href="#n8" name="n8">8</a>
<a href="#n9" name="n9">9</a>
<strong><a href="#n10" name="n10">10</a></strong>
<a href="#n11" name="n11">11</a>
<a href="#n12" name="n12">12</a>
<a href="#n13" name="n13">13</a>
<a href="#n14" name="n14">14</a>
<a href="#n15" name="n15">15</a>
<a href="#n16" name="n16">16</a>
<a href="#n17" name="n17">17</a>
<a href="#n18" name="n18">18</a>
<a href="#n19" name="n19">19</a>
<strong><a href="#n20" name="n20">20</a></strong>
<a href="#n21" name="n21">21</a>
<a href="#n22" name="n22">22</a>
</pre></td>
  <td class="code"><pre>
<span class="keyword">class</span> <span class="class">vector4f</span>
{
<span class="directive">public</span>:

    <span class="directive">inline</span> vector4f2() {}
    <span class="directive">inline</span> vector4f2(__m128 rhs) : m_value(rhs) {}

    <span class="directive">inline</span> vector4f2&amp; <span class="directive">operator</span>=(__m128 rhs)
        {
            m_value = rhs;
            <span class="keyword">return</span> *<span class="local-variable">this</span>;
        }

    <span class="directive">inline</span> <span class="directive">operator</span> __m128() <span class="directive">const</span> { <span class="keyword">return</span> m_value; }

<span class="directive">private</span>:

        __m128 m_value;
};

<span class="directive">inline</span> vector4f2 <span class="directive">operator</span>+(vector4f2 lhs, vector4f2 rhs) { <span class="keyword">return</span> _mm_add_ps(lhs,rhs); }
</pre></td>
</tr></table>
 </figure></notextile></div>

<p>Now if we dump the assembly code of the test_sse_add function we defined in the beginning, here is what we get:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>simd_test.cpp </span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
</pre></td>
  <td class="code"><pre>
<span class="comment">// test_sse_a asm:</span>
   <span class="integer">0</span>:    c5 f8 <span class="integer">58</span> c1              vaddps %xmm1,%xmm0,%xmm0
   <span class="integer">4</span>:    c3                       retq   
   <span class="integer">5</span>:    <span class="integer">66</span> <span class="integer">66</span> <span class="float">2</span>e <span class="float">0f</span> <span class="float">1f</span> <span class="integer">84</span> <span class="octal">00</span>     data32 nopw %cs:<span class="hex">0x0</span>(%rax,%rax,<span class="integer">1</span>)
   c:    <span class="octal">00</span> <span class="octal">00</span> <span class="octal">00</span> <span class="octal">00</span> 
</pre></td>
</tr></table>
 </figure></notextile></div>

<p>That’s exactly the same code as the one generated by pure stateless functions. So the indirection of the wrapper doesn’t introduce any
overhead. Since the only change we’ve made from the previous wrapper is to remove the CRTP layer, we have the culprit for the overhead
we noticed in the beginning: the CRTP layer.</p>

<p>I first thought of a Empty Base Optimization problem, but printing the size of both implementations of the wrapper proved me wrong: in both
case, the size of the wrapper is 16, so it fits in the XMM registers. So I must admit, I still have no explanation for this problem.</p>

<p>In the next section, I will consider the wrapper implementation that doesn’t use CRTP. Now that we’ve fixed this issue, let’s
see if operators overload prevents the compiler from proper instructions reordering during optimization.</p>

<h2 id="operators-overload">4. Operators overload</h2>

<p>For this test, I use the following functions:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>simd_test2.cpp </span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
<a href="#n7" name="n7">7</a>
<a href="#n8" name="n8">8</a>
<a href="#n9" name="n9">9</a>
<strong><a href="#n10" name="n10">10</a></strong>
<a href="#n11" name="n11">11</a>
<a href="#n12" name="n12">12</a>
<a href="#n13" name="n13">13</a>
<a href="#n14" name="n14">14</a>
<a href="#n15" name="n15">15</a>
</pre></td>
  <td class="code"><pre>
vector4f2 test_sse_b2(vector4f2 a, vector4f2 b, vector4f2 c, vector4f2 d)
{
    <span class="keyword">return</span> add(mul(a,b),mul(c,d));
}

vector4f2 test_sse_c2(vector4f2 a, vector4f2 b, vector4f2 c, vector4f2 d)
{
    <span class="keyword">return</span> add(add(mul(a,b),div(c,d)),sub(div(c,b),mul(a,d)));
}

vector4f2 test_sse_d2(vector4f2 a, vector4f2 b, vector4f2 c, vector4f2 d)
{
    <span class="keyword">return</span> mul(test_sse_c2(a,b,c,d),test_sse_b2(a,b,c,d));
}
</pre></td>
</tr></table>
 </figure></notextile></div>

<p>And the equivalent functions for wrappers:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>simd_test.cpp </span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
<a href="#n7" name="n7">7</a>
<a href="#n8" name="n8">8</a>
<a href="#n9" name="n9">9</a>
<strong><a href="#n10" name="n10">10</a></strong>
<a href="#n11" name="n11">11</a>
<a href="#n12" name="n12">12</a>
<a href="#n13" name="n13">13</a>
<a href="#n14" name="n14">14</a>
<a href="#n15" name="n15">15</a>
</pre></td>
  <td class="code"><pre>
vector4f test_sse_b(vector4f a, vector4f b, vector4f c, vector4f d)
{
    <span class="keyword">return</span> a*b + c*d;
}

vector4f test_sse_c(vector4f a, vector4f b, vector4f c, vector4f d)
{
    <span class="keyword">return</span> (a*b + c/d) + (c/b - a*d);
}

vector4f test_sse_d(vector4f a, vector4f b, vector4f c, vector4f d)
{
    <span class="keyword">return</span> test_sse_c(a,b,c,d) * test_sse_b(a,b,c,d);
}
</pre></td>
</tr></table>
 </figure></notextile></div>

<p>Here the parenthesis in <strong>test_sse_c</strong> ensure the compiler generates the same syntactic tree for both implementations; indeed, if we omitted the brackets, the code would have been almost equivalent to:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>simd_test2_bis.cpp</span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
<a href="#n7" name="n7">7</a>
</pre></td>
  <td class="code"><pre>
<span class="comment">// same code for test_sse_b2 and test_sse_d2</span>

vector4f2 test_sse_c2(vector4f2 a, vector4f2 b, vector4f2 c, vector4f2 d)
{
    <span class="keyword">return</span> sub(add(div(c,b),add(mul(a,b),div(c,d))),mul(a,d));
}
</pre></td>
</tr></table>
 </figure></notextile></div>

<p>Here is the generated assembly code with explanations in comments:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>simd_test.asm </span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
<a href="#n7" name="n7">7</a>
<a href="#n8" name="n8">8</a>
<a href="#n9" name="n9">9</a>
<strong><a href="#n10" name="n10">10</a></strong>
<a href="#n11" name="n11">11</a>
<a href="#n12" name="n12">12</a>
<a href="#n13" name="n13">13</a>
<a href="#n14" name="n14">14</a>
<a href="#n15" name="n15">15</a>
<a href="#n16" name="n16">16</a>
<a href="#n17" name="n17">17</a>
<a href="#n18" name="n18">18</a>
<a href="#n19" name="n19">19</a>
<strong><a href="#n20" name="n20">20</a></strong>
<a href="#n21" name="n21">21</a>
<a href="#n22" name="n22">22</a>
<a href="#n23" name="n23">23</a>
<a href="#n24" name="n24">24</a>
<a href="#n25" name="n25">25</a>
<a href="#n26" name="n26">26</a>
<a href="#n27" name="n27">27</a>
<a href="#n28" name="n28">28</a>
</pre></td>
  <td class="code"><pre>
<span class="comment">// test_sse_d</span>
  <span class="integer">40</span>:    c5 f8 <span class="integer">59</span> e1              vmulps %xmm1,%xmm0,%xmm4 <span class="comment">// a*b in xmm4</span>
  <span class="integer">44</span>:    c5 e8 <span class="float">5</span>e c9              vdivps %xmm1,%xmm2,%xmm1 <span class="comment">// c/b in xmm1</span>
  <span class="integer">48</span>:    c5 f8 <span class="integer">59</span> c3              vmulps %xmm3,%xmm0,%xmm0 <span class="comment">// a*d in xmm0</span>
  <span class="integer">4</span>c:    c5 e8 <span class="integer">59</span> eb              vmulps %xmm3,%xmm2,%xmm5 <span class="comment">// c*d in xmm5</span>
  <span class="integer">50</span>:    c5 d8 <span class="integer">58</span> ed              vaddps %xmm5,%xmm4,%xmm5 <span class="comment">// a*b + c*d in xmm5</span>
  <span class="integer">54</span>:    c5 f0 <span class="integer">5</span>c c8              vsubps %xmm0,%xmm1,%xmm1 <span class="comment">// c/b - a*d in xmm1</span>
  <span class="integer">58</span>:    c5 e8 <span class="float">5</span>e c3              vdivps %xmm3,%xmm2,%xmm0 <span class="comment">// c/d in xmm0</span>
  <span class="integer">5</span>c:    c5 d8 <span class="integer">58</span> c0              vaddps %xmm0,%xmm4,%xmm0 <span class="comment">// a*b + c/d in xmm0</span>
  <span class="integer">60</span>:    c5 f8 <span class="integer">58</span> c1              vaddps %xmm1,%xmm0,%xmm0 <span class="comment">// a*b + c/d + c/b - a*d in xmm0</span>
  <span class="integer">64</span>:    c5 f8 <span class="integer">59</span> c5              vmulps %xmm5,%xmm0,%xmm0 <span class="comment">// (a*b + c*d) * xmm0 in xmm0</span>
  <span class="integer">68</span>:    c3                       retq
  <span class="integer">69</span>:    <span class="float">0f</span> <span class="float">1f</span> <span class="integer">80</span> <span class="octal">00</span> <span class="octal">00</span> <span class="octal">00</span> <span class="octal">00</span>     nopl   <span class="hex">0x0</span>(%rax)

<span class="comment">// test_sse_d2</span>
  <span class="integer">40</span>:    c5 f8 <span class="integer">59</span> e1              vmulps %xmm1,%xmm0,%xmm4
  <span class="integer">44</span>:    c5 e8 <span class="float">5</span>e c9              vdivps %xmm1,%xmm2,%xmm1
  <span class="integer">48</span>:    c5 f8 <span class="integer">59</span> c3              vmulps %xmm3,%xmm0,%xmm0
  <span class="integer">4</span>c:    c5 e8 <span class="integer">59</span> eb              vmulps %xmm3,%xmm2,%xmm5
  <span class="integer">50</span>:    c5 d8 <span class="integer">58</span> ed              vaddps %xmm5,%xmm4,%xmm5
  <span class="integer">54</span>:    c5 f0 <span class="integer">5</span>c c8              vsubps %xmm0,%xmm1,%xmm1
  <span class="integer">58</span>:    c5 e8 <span class="float">5</span>e c3              vdivps %xmm3,%xmm2,%xmm0
  <span class="integer">5</span>c:    c5 d8 <span class="integer">58</span> c0              vaddps %xmm0,%xmm4,%xmm0
  <span class="integer">60</span>:    c5 f8 <span class="integer">58</span> c1              vaddps %xmm1,%xmm0,%xmm0
  <span class="integer">64</span>:    c5 f8 <span class="integer">59</span> c5              vmulps %xmm5,%xmm0,%xmm0
  <span class="integer">68</span>:    c3                       retq
  <span class="integer">69</span>:    <span class="float">0f</span> <span class="float">1f</span> <span class="integer">80</span> <span class="octal">00</span> <span class="octal">00</span> <span class="octal">00</span> <span class="octal">00</span>     nopl   <span class="hex">0x0</span>(%rax)
</pre></td>
</tr></table>
 </figure></notextile></div>

<p>The generated assembly codes for <strong>test_sse_d</strong> and <strong>test_sse_d2</strong> are exactly the sames. Operators overloads and equivalent stateless functions generally produces the same assembly code provided that the syntax tree is the same in both implementations. Indeed, the evaluation order of operators arguments and functions arguments may differ, making it impossible to have the same syntax tree in both implementations when using non-commutative operators.</p>

<p>Now what if we mix computation instructions with loop, load and store ? Consider the following piece of code:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>simd_test.cpp </span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
<a href="#n7" name="n7">7</a>
<a href="#n8" name="n8">8</a>
<a href="#n9" name="n9">9</a>
<strong><a href="#n10" name="n10">10</a></strong>
<a href="#n11" name="n11">11</a>
<a href="#n12" name="n12">12</a>
<a href="#n13" name="n13">13</a>
<a href="#n14" name="n14">14</a>
<a href="#n15" name="n15">15</a>
<a href="#n16" name="n16">16</a>
<a href="#n17" name="n17">17</a>
<a href="#n18" name="n18">18</a>
<a href="#n19" name="n19">19</a>
<strong><a href="#n20" name="n20">20</a></strong>
<a href="#n21" name="n21">21</a>
<a href="#n22" name="n22">22</a>
</pre></td>
  <td class="code"><pre>
<span class="directive">void</span> test_sse_e(<span class="directive">const</span> std::vector&lt;<span class="predefined-type">float</span>&gt;&amp; a,
                <span class="directive">const</span> std::vector&lt;<span class="predefined-type">float</span>&gt;&amp; b,
                <span class="directive">const</span> std::vector&lt;<span class="predefined-type">float</span>&gt;&amp; c,
                <span class="directive">const</span> std::vector&lt;<span class="predefined-type">float</span>&gt;&amp; d,
                std::vector&lt;<span class="predefined-type">float</span>&gt;&amp; e)
{
    <span class="comment">// typedef vector4f2 for test_sse_e2 implementation</span>
    <span class="keyword">typedef</span> vector4f vec_type;
    size_t bound = a.size()/<span class="integer">4</span>;
    <span class="keyword">for</span>(size_t i = <span class="integer">0</span>; i &lt; bound; i += <span class="integer">4</span>)
    {
        vec_type av = load_a2(&amp;a[i]);
        vec_type bv = load_a2(&amp;b[i]);
        vec_type cv = load_a2(&amp;c[i]);
        vec_type dv = load_a2(&amp;d[i]);

    <span class="comment">// vec_type ev = test_sse_d2(av,bv,cv,dv); for test_sse_e2 implementation</span>
        vec_type ev = test_sse_d(av,bv,cv,dv);
        store_a(&amp;e[i],ev);
    }
}
</pre></td>
</tr></table>
 </figure></notextile></div>

<p>Again, the generated assembly code is the same for both implementations:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>simd_test.asm</span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
<a href="#n7" name="n7">7</a>
<a href="#n8" name="n8">8</a>
<a href="#n9" name="n9">9</a>
<strong><a href="#n10" name="n10">10</a></strong>
<a href="#n11" name="n11">11</a>
<a href="#n12" name="n12">12</a>
<a href="#n13" name="n13">13</a>
<a href="#n14" name="n14">14</a>
<a href="#n15" name="n15">15</a>
<a href="#n16" name="n16">16</a>
<a href="#n17" name="n17">17</a>
<a href="#n18" name="n18">18</a>
<a href="#n19" name="n19">19</a>
<strong><a href="#n20" name="n20">20</a></strong>
<a href="#n21" name="n21">21</a>
<a href="#n22" name="n22">22</a>
<a href="#n23" name="n23">23</a>
<a href="#n24" name="n24">24</a>
<a href="#n25" name="n25">25</a>
<a href="#n26" name="n26">26</a>
<a href="#n27" name="n27">27</a>
<a href="#n28" name="n28">28</a>
<a href="#n29" name="n29">29</a>
<strong><a href="#n30" name="n30">30</a></strong>
<a href="#n31" name="n31">31</a>
<a href="#n32" name="n32">32</a>
<a href="#n33" name="n33">33</a>
<a href="#n34" name="n34">34</a>
<a href="#n35" name="n35">35</a>
<a href="#n36" name="n36">36</a>
<a href="#n37" name="n37">37</a>
<a href="#n38" name="n38">38</a>
<a href="#n39" name="n39">39</a>
<strong><a href="#n40" name="n40">40</a></strong>
<a href="#n41" name="n41">41</a>
<a href="#n42" name="n42">42</a>
<a href="#n43" name="n43">43</a>
<a href="#n44" name="n44">44</a>
<a href="#n45" name="n45">45</a>
<a href="#n46" name="n46">46</a>
<a href="#n47" name="n47">47</a>
<a href="#n48" name="n48">48</a>
<a href="#n49" name="n49">49</a>
<strong><a href="#n50" name="n50">50</a></strong>
<a href="#n51" name="n51">51</a>
<a href="#n52" name="n52">52</a>
<a href="#n53" name="n53">53</a>
<a href="#n54" name="n54">54</a>
<a href="#n55" name="n55">55</a>
<a href="#n56" name="n56">56</a>
<a href="#n57" name="n57">57</a>
<a href="#n58" name="n58">58</a>
<a href="#n59" name="n59">59</a>
<strong><a href="#n60" name="n60">60</a></strong>
<a href="#n61" name="n61">61</a>
<a href="#n62" name="n62">62</a>
<a href="#n63" name="n63">63</a>
<a href="#n64" name="n64">64</a>
<a href="#n65" name="n65">65</a>
<a href="#n66" name="n66">66</a>
<a href="#n67" name="n67">67</a>
<a href="#n68" name="n68">68</a>
</pre></td>
  <td class="code"><pre>
<span class="comment">// test_sse_e:</span>
  <span class="integer">70</span>:    <span class="integer">4</span>c <span class="integer">8</span>b <span class="float">0f</span>                 mov    (%rdi),%r9
  <span class="integer">73</span>:    <span class="integer">48</span> <span class="integer">8</span>b <span class="float">7f</span> <span class="integer">08</span>              mov    <span class="hex">0x8</span>(%rdi),%rdi
  <span class="integer">77</span>:    <span class="integer">4</span>c <span class="integer">29</span> cf                 sub    %r9,%rdi
  <span class="integer">7</span>a:    <span class="integer">48</span> c1 ff <span class="octal">02</span>              sar    $<span class="hex">0x2</span>,%rdi
  <span class="float">7</span>e:    <span class="integer">48</span> c1 ef <span class="octal">02</span>              shr    $<span class="hex">0x2</span>,%rdi
  <span class="integer">82</span>:    <span class="integer">48</span> <span class="integer">85</span> ff                 test   %rdi,%rdi
  <span class="integer">85</span>:    <span class="integer">74</span> <span class="integer">5</span>d                    je     e4 &lt;_ZN4simd11test_sse_eERKSt6vectorIfSaIfEES4_S4_S4_RS2_+<span class="hex">0x74</span>&gt;
  <span class="integer">87</span>:    <span class="integer">4</span>c <span class="integer">8</span>b <span class="integer">16</span>                 mov    (%rsi),%r10
  <span class="integer">8</span>a:    <span class="integer">31</span> c0                    <span class="keyword">xor</span>    %eax,%eax
  <span class="integer">8</span>c:    <span class="integer">48</span> <span class="integer">8</span>b <span class="integer">32</span>                 mov    (%rdx),%rsi
  <span class="float">8f</span>:    <span class="integer">48</span> <span class="integer">8</span>b <span class="integer">09</span>                 mov    (%rcx),%rcx
  <span class="integer">92</span>:    <span class="integer">49</span> <span class="integer">8</span>b <span class="integer">10</span>                 mov    (%r8),%rdx
  <span class="integer">95</span>:    <span class="float">0f</span> <span class="float">1f</span> <span class="octal">00</span>                 nopl   (%rax)
  <span class="integer">98</span>:    c5 f8 <span class="integer">28</span> <span class="integer">0</span>c <span class="integer">86</span>           vmovaps (%rsi,%rax,<span class="integer">4</span>),%xmm1
  <span class="integer">9</span>d:    c5 f8 <span class="integer">28</span> <span class="octal">04</span> <span class="integer">81</span>           vmovaps (%rcx,%rax,<span class="integer">4</span>),%xmm0
  a2:    c4 c1 <span class="integer">78</span> <span class="integer">28</span> <span class="integer">24</span> <span class="integer">81</span>        vmovaps (%r9,%rax,<span class="integer">4</span>),%xmm4
  a8:    c4 c1 <span class="integer">78</span> <span class="integer">28</span> <span class="integer">1</span>c <span class="integer">82</span>        vmovaps (%r10,%rax,<span class="integer">4</span>),%xmm3
  ae:    c5 f0 <span class="integer">59</span> e8              vmulps %xmm0,%xmm1,%xmm5
  b2:    c5 d8 <span class="integer">59</span> d3              vmulps %xmm3,%xmm4,%xmm2
  b6:    c5 d8 <span class="integer">59</span> e0              vmulps %xmm0,%xmm4,%xmm4
  ba:    c5 f0 <span class="float">5</span>e db              vdivps %xmm3,%xmm1,%xmm3
  be:    c5 e8 <span class="integer">58</span> ed              vaddps %xmm5,%xmm2,%xmm5
  c2:    c5 f0 <span class="float">5</span>e c0              vdivps %xmm0,%xmm1,%xmm0
  c6:    c5 e0 <span class="integer">5</span>c dc              vsubps %xmm4,%xmm3,%xmm3
  ca:    c5 e8 <span class="integer">58</span> d0              vaddps %xmm0,%xmm2,%xmm2
  ce:    c5 e8 <span class="integer">58</span> d3              vaddps %xmm3,%xmm2,%xmm2
  d2:    c5 e8 <span class="integer">59</span> d5              vmulps %xmm5,%xmm2,%xmm2
  d6:    c5 f8 <span class="integer">29</span> <span class="integer">14</span> <span class="integer">82</span>           vmovaps %xmm2,(%rdx,%rax,<span class="integer">4</span>)
  db:    <span class="integer">48</span> <span class="integer">83</span> c0 <span class="octal">04</span>              add    $<span class="hex">0x4</span>,%rax
  df:    <span class="integer">48</span> <span class="integer">39</span> c7                 cmp    %rax,%rdi
  e2:    <span class="integer">77</span> b4                    ja     <span class="integer">98</span> &lt;_ZN4simd11test_sse_eERKSt6vectorIfSaIfEES4_S4_S4_RS2_+<span class="hex">0x28</span>&gt;
  e4:    f3 c3                    repz retq

<span class="comment">// test_sse_e2</span>
  <span class="integer">70</span>:    <span class="integer">4</span>c <span class="integer">8</span>b <span class="float">0f</span>                 mov    (%rdi),%r9
  <span class="integer">73</span>:    <span class="integer">48</span> <span class="integer">8</span>b <span class="float">7f</span> <span class="integer">08</span>              mov    <span class="hex">0x8</span>(%rdi),%rdi
  <span class="integer">77</span>:    <span class="integer">4</span>c <span class="integer">29</span> cf                 sub    %r9,%rdi
  <span class="integer">7</span>a:    <span class="integer">48</span> c1 ff <span class="octal">02</span>              sar    $<span class="hex">0x2</span>,%rdi
  <span class="float">7</span>e:    <span class="integer">48</span> c1 ef <span class="octal">02</span>              shr    $<span class="hex">0x2</span>,%rdi
  <span class="integer">82</span>:    <span class="integer">48</span> <span class="integer">85</span> ff                 test   %rdi,%rdi
  <span class="integer">85</span>:    <span class="integer">74</span> <span class="integer">5</span>d                    je     e4 &lt;_ZN4simd11test_sse_e2ERKSt6vectorIfSaIfEES4_S4_S4_RS2_+<span class="hex">0x74</span>&gt;
  <span class="integer">87</span>:    <span class="integer">4</span>c <span class="integer">8</span>b <span class="integer">16</span>                 mov    (%rsi),%r10
  <span class="integer">8</span>a:    <span class="integer">31</span> c0                    <span class="keyword">xor</span>    %eax,%eax
  <span class="integer">8</span>c:    <span class="integer">48</span> <span class="integer">8</span>b <span class="integer">32</span>                 mov    (%rdx),%rsi
  <span class="float">8f</span>:    <span class="integer">48</span> <span class="integer">8</span>b <span class="integer">09</span>                 mov    (%rcx),%rcx
  <span class="integer">92</span>:    <span class="integer">49</span> <span class="integer">8</span>b <span class="integer">10</span>                 mov    (%r8),%rdx
  <span class="integer">95</span>:    <span class="float">0f</span> <span class="float">1f</span> <span class="octal">00</span>                 nopl   (%rax)
  <span class="integer">98</span>:    c5 f8 <span class="integer">28</span> <span class="integer">0</span>c <span class="integer">86</span>           vmovaps (%rsi,%rax,<span class="integer">4</span>),%xmm1
  <span class="integer">9</span>d:    c5 f8 <span class="integer">28</span> <span class="octal">04</span> <span class="integer">81</span>           vmovaps (%rcx,%rax,<span class="integer">4</span>),%xmm0
  a2:    c4 c1 <span class="integer">78</span> <span class="integer">28</span> <span class="integer">24</span> <span class="integer">81</span>        vmovaps (%r9,%rax,<span class="integer">4</span>),%xmm4
  a8:    c4 c1 <span class="integer">78</span> <span class="integer">28</span> <span class="integer">1</span>c <span class="integer">82</span>        vmovaps (%r10,%rax,<span class="integer">4</span>),%xmm3
  ae:    c5 f0 <span class="integer">59</span> e8              vmulps %xmm0,%xmm1,%xmm5
  b2:    c5 d8 <span class="integer">59</span> d3              vmulps %xmm3,%xmm4,%xmm2
  b6:    c5 d8 <span class="integer">59</span> e0              vmulps %xmm0,%xmm4,%xmm4
  ba:    c5 f0 <span class="float">5</span>e db              vdivps %xmm3,%xmm1,%xmm3
  be:    c5 e8 <span class="integer">58</span> ed              vaddps %xmm5,%xmm2,%xmm5
  c2:    c5 f0 <span class="float">5</span>e c0              vdivps %xmm0,%xmm1,%xmm0
  c6:    c5 e0 <span class="integer">5</span>c dc              vsubps %xmm4,%xmm3,%xmm3
  ca:    c5 e8 <span class="integer">58</span> d0              vaddps %xmm0,%xmm2,%xmm2
  ce:    c5 e8 <span class="integer">58</span> d3              vaddps %xmm3,%xmm2,%xmm2
  d2:    c5 e8 <span class="integer">59</span> d5              vmulps %xmm5,%xmm2,%xmm2
  d6:    c5 f8 <span class="integer">29</span> <span class="integer">14</span> <span class="integer">82</span>           vmovaps %xmm2,(%rdx,%rax,<span class="integer">4</span>)
  db:    <span class="integer">48</span> <span class="integer">83</span> c0 <span class="octal">04</span>              add    $<span class="hex">0x4</span>,%rax
  df:    <span class="integer">48</span> <span class="integer">39</span> c7                 cmp    %rax,%rdi
  e2:    <span class="integer">77</span> b4                    ja     <span class="integer">98</span> &lt;_ZN4simd11test_sse_e2ERKSt6vectorIfSaIfEES4_S4_S4_RS2_+<span class="hex">0x28</span>&gt;
  e4:    f3 c3                    repz retq 
</pre></td>
</tr></table>
 </figure></notextile></div>

<p>To conclude, operators overloads don’t prevent the compiler to reorder instructions during optimization, and thus they don’t introduce any performance issue. Since they allow you to write code more readable and easier to maintain, it would be a shame not to use them.</p>

<h2 id="refactoring-the-wrappers-without-crtp">5. Refactoring the wrappers without CRTP</h2>

<p>Before we consider refactoring the wrappers, let’s see the overhead of the CRTP layer in a more realistic code. Using the <strong>test_sse_d</strong> and <strong>test_sse_e</strong> functions of the previous section with the first version of the wrappers (the one with CRTP), here is the result of objdump:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>test_sse.asm </span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
<a href="#n7" name="n7">7</a>
<a href="#n8" name="n8">8</a>
<a href="#n9" name="n9">9</a>
<strong><a href="#n10" name="n10">10</a></strong>
<a href="#n11" name="n11">11</a>
<a href="#n12" name="n12">12</a>
<a href="#n13" name="n13">13</a>
<a href="#n14" name="n14">14</a>
<a href="#n15" name="n15">15</a>
<a href="#n16" name="n16">16</a>
<a href="#n17" name="n17">17</a>
<a href="#n18" name="n18">18</a>
<a href="#n19" name="n19">19</a>
<strong><a href="#n20" name="n20">20</a></strong>
<a href="#n21" name="n21">21</a>
<a href="#n22" name="n22">22</a>
<a href="#n23" name="n23">23</a>
<a href="#n24" name="n24">24</a>
<a href="#n25" name="n25">25</a>
<a href="#n26" name="n26">26</a>
<a href="#n27" name="n27">27</a>
<a href="#n28" name="n28">28</a>
<a href="#n29" name="n29">29</a>
<strong><a href="#n30" name="n30">30</a></strong>
<a href="#n31" name="n31">31</a>
<a href="#n32" name="n32">32</a>
<a href="#n33" name="n33">33</a>
<a href="#n34" name="n34">34</a>
<a href="#n35" name="n35">35</a>
<a href="#n36" name="n36">36</a>
<a href="#n37" name="n37">37</a>
<a href="#n38" name="n38">38</a>
<a href="#n39" name="n39">39</a>
<strong><a href="#n40" name="n40">40</a></strong>
<a href="#n41" name="n41">41</a>
<a href="#n42" name="n42">42</a>
<a href="#n43" name="n43">43</a>
<a href="#n44" name="n44">44</a>
<a href="#n45" name="n45">45</a>
<a href="#n46" name="n46">46</a>
<a href="#n47" name="n47">47</a>
<a href="#n48" name="n48">48</a>
<a href="#n49" name="n49">49</a>
<strong><a href="#n50" name="n50">50</a></strong>
<a href="#n51" name="n51">51</a>
<a href="#n52" name="n52">52</a>
<a href="#n53" name="n53">53</a>
<a href="#n54" name="n54">54</a>
<a href="#n55" name="n55">55</a>
<a href="#n56" name="n56">56</a>
</pre></td>
  <td class="code"><pre>
<span class="comment">// test_sse_d</span>
  <span class="integer">70</span>:    c4 c1 <span class="integer">78</span> <span class="integer">28</span> <span class="octal">00</span>           vmovaps (%r8),%xmm0
  <span class="integer">75</span>:    <span class="integer">48</span> <span class="integer">89</span> f8                 mov    %rdi,%rax
  <span class="integer">78</span>:    c5 f8 <span class="integer">28</span> <span class="integer">09</span>              vmovaps (%rcx),%xmm1
  <span class="integer">7</span>c:    c5 f8 <span class="integer">28</span> <span class="integer">1</span>a              vmovaps (%rdx),%xmm3
  <span class="integer">80</span>:    c5 f8 <span class="integer">28</span> <span class="integer">26</span>              vmovaps (%rsi),%xmm4
  <span class="integer">84</span>:    c5 f0 <span class="integer">59</span> e8              vmulps %xmm0,%xmm1,%xmm5
  <span class="integer">88</span>:    c5 d8 <span class="integer">59</span> d3              vmulps %xmm3,%xmm4,%xmm2
  <span class="integer">8</span>c:    c5 d8 <span class="integer">59</span> e0              vmulps %xmm0,%xmm4,%xmm4
  <span class="integer">90</span>:    c5 f0 <span class="float">5</span>e c0              vdivps %xmm0,%xmm1,%xmm0
  <span class="integer">94</span>:    c5 e8 <span class="integer">58</span> ed              vaddps %xmm5,%xmm2,%xmm5
  <span class="integer">98</span>:    c5 f0 <span class="float">5</span>e db              vdivps %xmm3,%xmm1,%xmm3
  <span class="integer">9</span>c:    c5 e8 <span class="integer">58</span> d0              vaddps %xmm0,%xmm2,%xmm2
  a0:    c5 e8 <span class="integer">58</span> d3              vaddps %xmm3,%xmm2,%xmm2
  a4:    c5 e8 <span class="integer">5</span>c e4              vsubps %xmm4,%xmm2,%xmm4
  a8:    c5 d8 <span class="integer">59</span> e5              vmulps %xmm5,%xmm4,%xmm4
  ac:    c5 f8 <span class="integer">29</span> <span class="integer">27</span>              vmovaps %xmm4,(%rdi)
  b0:    c3                       retq   
  b1:    <span class="integer">66</span> <span class="integer">66</span> <span class="integer">66</span> <span class="integer">66</span> <span class="integer">66</span> <span class="integer">66</span> <span class="float">2</span>e     data32 data32 data32 data32 data32 nopw %cs:<span class="hex">0x0</span>(%rax,%rax,<span class="integer">1</span>)
  b8:    <span class="float">0f</span> <span class="float">1f</span> <span class="integer">84</span> <span class="octal">00</span> <span class="octal">00</span> <span class="octal">00</span> <span class="octal">00</span> 
  bf:    <span class="octal">00</span> 

<span class="comment">// test_sse_e</span>
  c0:    <span class="integer">4</span>c <span class="integer">8</span>b <span class="float">0f</span>                 mov    (%rdi),%r9
  c3:    <span class="integer">48</span> <span class="integer">8</span>b <span class="float">7f</span> <span class="integer">08</span>              mov    <span class="hex">0x8</span>(%rdi),%rdi
  c7:    <span class="integer">4</span>c <span class="integer">29</span> cf                 sub    %r9,%rdi
  ca:    <span class="integer">48</span> c1 ff <span class="octal">02</span>              sar    $<span class="hex">0x2</span>,%rdi
  ce:    <span class="integer">48</span> c1 ef <span class="octal">02</span>              shr    $<span class="hex">0x2</span>,%rdi
  d2:    <span class="integer">48</span> <span class="integer">85</span> ff                 test   %rdi,%rdi
  d5:    <span class="integer">74</span> <span class="integer">5</span>d                    je     <span class="integer">134</span> &lt;_ZN4simd10test_sse_eERKSt6vectorIfSaIfEES4_S4_S4_RS2_+<span class="hex">0x74</span>&gt;
  d7:    <span class="integer">4</span>c <span class="integer">8</span>b <span class="integer">16</span>                 mov    (%rsi),%r10
  da:    <span class="integer">31</span> c0                    <span class="keyword">xor</span>    %eax,%eax
  dc:    <span class="integer">48</span> <span class="integer">8</span>b <span class="integer">32</span>                 mov    (%rdx),%rsi
  df:    <span class="integer">48</span> <span class="integer">8</span>b <span class="integer">09</span>                 mov    (%rcx),%rcx
  e2:    <span class="integer">49</span> <span class="integer">8</span>b <span class="integer">10</span>                 mov    (%r8),%rdx
  e5:    <span class="float">0f</span> <span class="float">1f</span> <span class="octal">00</span>                 nopl   (%rax)
  e8:    c5 f8 <span class="integer">28</span> <span class="integer">0</span>c <span class="integer">86</span>           vmovaps (%rsi,%rax,<span class="integer">4</span>),%xmm1
  ed:    c5 f8 <span class="integer">28</span> <span class="octal">04</span> <span class="integer">81</span>           vmovaps (%rcx,%rax,<span class="integer">4</span>),%xmm0
  f2:    c4 c1 <span class="integer">78</span> <span class="integer">28</span> <span class="integer">24</span> <span class="integer">81</span>        vmovaps (%r9,%rax,<span class="integer">4</span>),%xmm4
  f8:    c4 c1 <span class="integer">78</span> <span class="integer">28</span> <span class="integer">1</span>c <span class="integer">82</span>        vmovaps (%r10,%rax,<span class="integer">4</span>),%xmm3
  fe:    c5 f0 <span class="integer">59</span> e8              vmulps %xmm0,%xmm1,%xmm5
 <span class="integer">102</span>:    c5 d8 <span class="integer">59</span> d3              vmulps %xmm3,%xmm4,%xmm2
 <span class="integer">106</span>:    c5 d8 <span class="integer">59</span> e0              vmulps %xmm0,%xmm4,%xmm4
 <span class="integer">10</span>a:    c5 f0 <span class="float">5</span>e c0              vdivps %xmm0,%xmm1,%xmm0
 <span class="integer">1</span><span class="float">0</span>e:    c5 e8 <span class="integer">58</span> ed              vaddps %xmm5,%xmm2,%xmm5
 <span class="integer">112</span>:    c5 f0 <span class="float">5</span>e db              vdivps %xmm3,%xmm1,%xmm3
 <span class="integer">116</span>:    c5 e8 <span class="integer">58</span> d0              vaddps %xmm0,%xmm2,%xmm2
 <span class="integer">11</span>a:    c5 e8 <span class="integer">58</span> d3              vaddps %xmm3,%xmm2,%xmm2
 <span class="integer">1</span><span class="float">1</span>e:    c5 e8 <span class="integer">5</span>c e4              vsubps %xmm4,%xmm2,%xmm4
 <span class="integer">122</span>:    c5 d8 <span class="integer">59</span> e5              vmulps %xmm5,%xmm4,%xmm4
 <span class="integer">126</span>:    c5 f8 <span class="integer">29</span> <span class="integer">24</span> <span class="integer">82</span>           vmovaps %xmm4,(%rdx,%rax,<span class="integer">4</span>)
 <span class="integer">12</span>b:    <span class="integer">48</span> <span class="integer">83</span> c0 <span class="octal">04</span>              add    $<span class="hex">0x4</span>,%rax
 <span class="integer">1</span><span class="float">2f</span>:    <span class="integer">48</span> <span class="integer">39</span> c7                 cmp    %rax,%rdi
 <span class="integer">132</span>:    <span class="integer">77</span> b4                    ja     e8 &lt;_ZN4simd10test_sse_eERKSt6vectorIfSaIfEES4_S4_S4_RS2_+<span class="hex">0x28</span>&gt;
 <span class="integer">134</span>:    f3 c3                    repz retq 
</pre></td>
</tr></table>
 </figure></notextile></div>

<p>In <strong>test_sse_d</strong>, we have six more instructions than in the previous version, these instructions are data transfer to the SIMD registers at the beginning of the function, and data transfer from the SIMD register at the end of the function. Now if we look at <strong>test_sse_e</strong>, we’ve got exactly the same code as in the previous section. The call to <strong>test_sse_d</strong> is inlined, and since the data transfer from and to SIMD registers is required by <strong>load_a</strong> and <strong>store_a</strong> functions, there is no need to keep the <strong>movaps</strong> instructions of <strong>test_sse_d</strong>. So if the functions working with wrappers are small enough to be inlined and if computation instructions are used between load and store functions, using the wrappers with CRTP should not introduce any overhead since the compiler will remove useless <strong>movaps</strong> instructions.</p>

<p>However, if you still want to refactor the wrappers but don’t want to repeat the boilerplate implementation of operators overloads, the alternative is to use preprocessor macros:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>simd_sse.hpp </span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
<a href="#n7" name="n7">7</a>
<a href="#n8" name="n8">8</a>
<a href="#n9" name="n9">9</a>
<strong><a href="#n10" name="n10">10</a></strong>
<a href="#n11" name="n11">11</a>
<a href="#n12" name="n12">12</a>
<a href="#n13" name="n13">13</a>
<a href="#n14" name="n14">14</a>
</pre></td>
  <td class="code"><pre>
<span class="preprocessor">#define</span> DEFINE_OPERATOR+=(RET_TYPE,ARG_TYPE)\
    <span class="directive">inline</span> RET_TYPE&amp; <span class="directive">operator</span>+=(<span class="directive">const</span> ARG_TYPE&amp; rhs)\
    {\
        *<span class="local-variable">this</span> = *<span class="local-variable">this</span> + rhs;\
        <span class="keyword">return</span> *<span class="local-variable">this</span>;\
    }
<span class="comment">// ... etc for other computed assignment operators</span>
<span class="preprocessor">#define</span> DEFINE_ASSIGNMENT_OPERATORS(TYPE,SCALAR_TYPE)\
    DEFINE_OPERATOR+=(TYPE,TYPE)\
    DEFINE_OPERATOR+=(TYPE,SCALAR_TYPE)\
    DEFINE_OPERATOR-=(TYPE,TYPE)\
    DEFINE_OPERATOR-=(TYPE,SCALAR_TYPE)\
    <span class="comment">// etc</span>
</pre></td>
</tr></table>
 </figure></notextile></div>

<p>This is much less elegant, but it comes with the guarantee that there won’t be any performance issue.</p>

<h2 id="conclusion">Conclusion</h2>

<p>Performance is not an intuitive domain; we have to check any assumption we make, because these assumptions can be legacy of time when compilers were inefficient or buggy, or a bias due to our misunderstood of some mechanisms of the language. Here we’ve seen that neither operator overloads nor constant reference argument instead of value argument introduce any performance issue with GCC, but this might be different with another compiler.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Writing C++ Wrappers for SIMD Intrinsics (5)]]></title>
    <link href="http://jmabille.github.io/blog/2014/10/25/writing-c-plus-plus-wrappers-for-simd-intrinsics-5/"/>
    <updated>2014-10-25T11:28:18+02:00</updated>
    <id>http://jmabille.github.io/blog/2014/10/25/writing-c-plus-plus-wrappers-for-simd-intrinsics-5</id>
    <content type="html"><![CDATA[<h2 id="making-the-code-more-generic">4. Making the code more generic</h2>

<p>In the previous section we saw how to plug the wrappers into existing code and ended up with the following loop:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>sample.cpp </span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
<a href="#n7" name="n7">7</a>
<a href="#n8" name="n8">8</a>
<a href="#n9" name="n9">9</a>
<strong><a href="#n10" name="n10">10</a></strong>
<a href="#n11" name="n11">11</a>
<a href="#n12" name="n12">12</a>
<a href="#n13" name="n13">13</a>
<a href="#n14" name="n14">14</a>
<a href="#n15" name="n15">15</a>
<a href="#n16" name="n16">16</a>
</pre></td>
  <td class="code"><pre>
std::vector&lt;<span class="predefined-type">float</span>&gt; a, b, c, d, e
<span class="comment">// Somewhere in the code the vectors are resized</span>
<span class="comment">// so they hold n elements</span>
<span class="keyword">for</span>(size_t i = <span class="integer">0</span>; i &lt; n/<span class="integer">4</span>; i+=<span class="integer">4</span>)
{
    vector4f av; av.load_a(&amp;a[i]);
    vector4f bv; bv.load_a(&amp;b[i]);
    vector4f cv; cv.load_a(&amp;c[i]);
    vector4f dv; dv.load_a(&amp;d[i]);

    vector4f ev = av*bv + cv*dv;
    ev.store_a(&amp;e[i]);
}
<span class="comment">// Remaining part of the loop</span>
<span class="comment">// ...</span>
</pre></td>
</tr></table>
 </figure></notextile></div>

<!-- more -->

<p>As said in the previous section, the first problem of this code is its lack of genericity; we are highly coupled with the
SIMD instruction set wrapped, and replacing it with another one requires code changes we should avoid. If we want to make
the code independant from the SIMD instruction set and the related wrapper, we need to hide the specifics of this instruction
set, that is, the vector type and its size (the number of scalars it holds).</p>

<h3 id="hiding-the-wrapper-type">4.1 Hiding the wrapper type</h3>

<p>We want to be able to select the right wrapper depending on the scalar type and the instruction set used. When talking about
selecting a type depending on another one, the first thing that comes to mind is type traits. Here our traits must contain the
wrapper type and its size associated with the scalar type used:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>simd_traits.hpp </span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
<a href="#n7" name="n7">7</a>
</pre></td>
  <td class="code"><pre>
<span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="class">T</span>&gt;
    <span class="keyword">struct</span> simd_traits
    {
        <span class="keyword">typedef</span> T type;
        <span class="directive">static</span> <span class="directive">const</span> size_t size = <span class="integer">1</span>;
    };
</pre></td>
</tr></table>
 </figure></notextile></div>

<p>The general definition of the traits class allows us to write code that works even for types that don’t have related
wrappers (numerical types defined by another user for instance). Then we need to specialize these definitions for float
and double, depending on the considered instruction set. Assume we can detect the instruction set available on our system
and save this information in a macro (we’ll see how to do that in a later section). The specialization of the traits
class will look like:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>simd.hpp</span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
<a href="#n7" name="n7">7</a>
<a href="#n8" name="n8">8</a>
<a href="#n9" name="n9">9</a>
<strong><a href="#n10" name="n10">10</a></strong>
<a href="#n11" name="n11">11</a>
<a href="#n12" name="n12">12</a>
<a href="#n13" name="n13">13</a>
<a href="#n14" name="n14">14</a>
<a href="#n15" name="n15">15</a>
<a href="#n16" name="n16">16</a>
<a href="#n17" name="n17">17</a>
<a href="#n18" name="n18">18</a>
<a href="#n19" name="n19">19</a>
<strong><a href="#n20" name="n20">20</a></strong>
<a href="#n21" name="n21">21</a>
<a href="#n22" name="n22">22</a>
<a href="#n23" name="n23">23</a>
<a href="#n24" name="n24">24</a>
<a href="#n25" name="n25">25</a>
<a href="#n26" name="n26">26</a>
<a href="#n27" name="n27">27</a>
<a href="#n28" name="n28">28</a>
<a href="#n29" name="n29">29</a>
<strong><a href="#n30" name="n30">30</a></strong>
</pre></td>
  <td class="code"><pre>
<span class="preprocessor">#ifdef</span> USE_SSE
<span class="keyword">template</span> &lt;&gt;
    <span class="keyword">struct</span> simd_traits&lt;<span class="predefined-type">float</span>&gt;
    {
        <span class="keyword">typedef</span> vector4f type;
        <span class="directive">static</span> <span class="directive">const</span> size_t size = <span class="integer">4</span>;
    };

<span class="keyword">template</span> &lt;&gt;
    <span class="keyword">struct</span> simd_traits&lt;<span class="predefined-type">double</span>&gt;
    {
        <span class="keyword">typedef</span> vector2d type;
        <span class="directive">static</span> <span class="directive">const</span> size_t size = <span class="integer">2</span>;
    };
<span class="preprocessor">#elif</span> USE_AVX
<span class="keyword">template</span> &lt;&gt;
    <span class="keyword">struct</span> simd_traits&lt;<span class="predefined-type">float</span>&gt;
    {
        <span class="keyword">typedef</span> vector8f type;
        <span class="directive">static</span> <span class="directive">const</span> size_t size = <span class="integer">8</span>;
    };

<span class="keyword">template</span> &lt;&gt;
    <span class="keyword">struct</span> simd_traits&lt;<span class="predefined-type">double</span>&gt;
    {
        <span class="keyword">typedef</span> vector4d type;
        <span class="directive">static</span> <span class="directive">const</span> size_t size = <span class="integer">4</span>;
    };
<span class="preprocessor">#endif</span>
</pre></td>
</tr></table>
 </figure></notextile></div>

<p>Now we can adapt the loop so it doesn’t explicitly refer to the vector4f type:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>sample.cpp </span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
<a href="#n7" name="n7">7</a>
<a href="#n8" name="n8">8</a>
<a href="#n9" name="n9">9</a>
<strong><a href="#n10" name="n10">10</a></strong>
<a href="#n11" name="n11">11</a>
<a href="#n12" name="n12">12</a>
<a href="#n13" name="n13">13</a>
<a href="#n14" name="n14">14</a>
<a href="#n15" name="n15">15</a>
<a href="#n16" name="n16">16</a>
<a href="#n17" name="n17">17</a>
</pre></td>
  <td class="code"><pre>
std::vector&lt;<span class="predefined-type">float</span>&gt; a,b,c,d,e;
<span class="comment">// ... resize a, b, c, d, and e so they hold n elements</span>
<span class="keyword">typedef</span> simd_traits&lt;<span class="predefined-type">float</span>&gt;::type vec_type;
size_t vec_size = simd_traits&lt;<span class="predefined-type">float</span>&gt;::size;
<span class="keyword">for</span>(size_t i = <span class="integer">0</span>; i &lt; n/vec_size; i += vec_size)
{
    vec_type av; av.load_a(&amp;a[i]);
    vec_type bv; bv.load_a(&amp;b[i]);
    vec_type cv; cv.load_a(&amp;c[i]);
    vec_type dv; dv.load_a(&amp;d[i]);

    vec_type ev = av*bv + cv*dv;
    ev.store_a(&amp;e[i]);
}
<span class="comment">// Remaining part of the loop</span>
<span class="comment">// ...</span>
</pre></td>
</tr></table>
 </figure></notextile></div>

<p>That’s it! If we need to compile this code on a system where AVX is available, we have nothing to do. The macro
USE_AVX will be defined, the specialization of simd_traits with vector8f as inner type will be instantiated,
and the loop will use the vector8f wrapper and the AVX intrinsics. However, there’s still a problem: we can
migrate to any SIMD instruction set for which a wrapper is available, but we can’t use types that don’t have
related wrappers. The simd_traits works fine even for user defined types, but the load and store functions are
available for wrappers only. We need to provide generic versions of these functions that work with any type.</p>

<h3 id="generic-load-an-store-functions">4.2 Generic load an store functions</h3>

<p>Actually, all we have to do is to provide two versions of these functions: one for types that don’t have related
wrappers, and one that works with wrappers. Template specialization can be of help here, but since partial
specialization is not possible for functions, let’s wrap them into a simd_functions_invoker class:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>simd.hpp </span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
<a href="#n7" name="n7">7</a>
<a href="#n8" name="n8">8</a>
<a href="#n9" name="n9">9</a>
<strong><a href="#n10" name="n10">10</a></strong>
<a href="#n11" name="n11">11</a>
<a href="#n12" name="n12">12</a>
<a href="#n13" name="n13">13</a>
<a href="#n14" name="n14">14</a>
<a href="#n15" name="n15">15</a>
<a href="#n16" name="n16">16</a>
<a href="#n17" name="n17">17</a>
<a href="#n18" name="n18">18</a>
<a href="#n19" name="n19">19</a>
<strong><a href="#n20" name="n20">20</a></strong>
<a href="#n21" name="n21">21</a>
<a href="#n22" name="n22">22</a>
<a href="#n23" name="n23">23</a>
<a href="#n24" name="n24">24</a>
<a href="#n25" name="n25">25</a>
<a href="#n26" name="n26">26</a>
<a href="#n27" name="n27">27</a>
<a href="#n28" name="n28">28</a>
<a href="#n29" name="n29">29</a>
<strong><a href="#n30" name="n30">30</a></strong>
<a href="#n31" name="n31">31</a>
<a href="#n32" name="n32">32</a>
<a href="#n33" name="n33">33</a>
<a href="#n34" name="n34">34</a>
<a href="#n35" name="n35">35</a>
<a href="#n36" name="n36">36</a>
<a href="#n37" name="n37">37</a>
<a href="#n38" name="n38">38</a>
<a href="#n39" name="n39">39</a>
<strong><a href="#n40" name="n40">40</a></strong>
</pre></td>
  <td class="code"><pre>
<span class="comment">// Common implementation for types that support vectorization</span>
<span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="class">T</span>, <span class="keyword">class</span> <span class="class">V</span>&gt;
    <span class="keyword">struct</span> simd_functions_invoker
    {
        <span class="directive">inline</span> <span class="directive">static</span> V
        set1(<span class="directive">const</span> T&amp; a) { <span class="keyword">return</span> V(a); }

        <span class="directive">inline</span> <span class="directive">static</span> V
        load_a(<span class="directive">const</span> T* src) { V res; res.load_a(src); <span class="keyword">return</span> res; }

        <span class="directive">inline</span> <span class="directive">static</span> V
        load_u(<span class="directive">const</span> T* src) { V res; res.load_u(src); <span class="keyword">return</span> res; }

        <span class="directive">inline</span> <span class="directive">static</span> <span class="directive">void</span>
        store_a(T* dst, <span class="directive">const</span> V&amp; src) { src.store_a(dst); }

        <span class="directive">inline</span> <span class="directive">static</span> <span class="directive">void</span>
        store_u(T* dst, <span class="directive">const</span> V&amp; src) { src.store_u(dst); }
    };

<span class="comment">// Specialization for types that don't support vectorization</span>
<span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="class">T</span>&gt;
    <span class="keyword">struct</span> simd_functions_invoker&lt;T,T&gt;
    {
        <span class="directive">inline</span> <span class="directive">static</span> T
        set1(<span class="directive">const</span> T&amp; a) { <span class="keyword">return</span> V(a); }

        <span class="directive">inline</span> <span class="directive">static</span> T
        load_a(<span class="directive">const</span> T* src) { <span class="keyword">return</span> *src; }

        <span class="directive">inline</span> <span class="directive">static</span> T
        load_u(<span class="directive">const</span> T* src) { <span class="keyword">return</span> *src; }

        <span class="directive">inline</span> <span class="directive">static</span> <span class="directive">void</span>
        store_a(T* dst, <span class="directive">const</span> T&amp; src) { *dst = src; }

        <span class="directive">inline</span> <span class="directive">static</span> <span class="directive">void</span>
        store_u(T* dst, <span class="directive">const</span> T&amp; src) { *dst = src; }
    };
</pre></td>
</tr></table>
 </figure></notextile></div>

<p>We’ve added the set1 function so we can intialize wrappers and scalar type from a single value in an
uniform way. Calling the generic functions would look like:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>sample.cpp </span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
</pre></td>
  <td class="code"><pre>
<span class="keyword">typedef</span> simd_traits&lt;<span class="predefined-type">float</span>&gt;::simd_type vec_type;
vec_type va = simd_functions_invoker&lt;<span class="predefined-type">float</span>,vec_type&gt;::load_a(a);
</pre></td>
</tr></table>
 </figure></notextile></div>

<p><a name="simd_load"></a>That’s too much verbose. Let’s add façade functions that deduce template parameters for us:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>simd.hpp </span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
<a href="#n7" name="n7">7</a>
<a href="#n8" name="n8">8</a>
<a href="#n9" name="n9">9</a>
<strong><a href="#n10" name="n10">10</a></strong>
<a href="#n11" name="n11">11</a>
<a href="#n12" name="n12">12</a>
<a href="#n13" name="n13">13</a>
<a href="#n14" name="n14">14</a>
<a href="#n15" name="n15">15</a>
<a href="#n16" name="n16">16</a>
<a href="#n17" name="n17">17</a>
<a href="#n18" name="n18">18</a>
<a href="#n19" name="n19">19</a>
<strong><a href="#n20" name="n20">20</a></strong>
</pre></td>
  <td class="code"><pre>
<span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="class">T</span>&gt; <span class="directive">inline</span> <span class="keyword">typename</span> simd_traits&lt;T&gt;::type
set1(<span class="directive">const</span> T&amp; a)
{ <span class="keyword">return</span> simd_functions_invoker&lt;T,<span class="keyword">typename</span> simd_traits&lt;T&gt;::type&gt;::set1(a); }

<span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="class">T</span>&gt; <span class="directive">inline</span> <span class="keyword">typename</span> simd_traits&lt;T&gt;::type
load_a(<span class="directive">const</span> T* src)
{ <span class="keyword">return</span> simd_functions_invoker&lt;T,<span class="keyword">typename</span> simd_traits&lt;T&gt;::type&gt;::load_a(src); }

<span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="class">T</span>&gt; <span class="directive">inline</span> <span class="keyword">typename</span> simd_traits&lt;T&gt;::type
load_u(<span class="directive">const</span> T* src)
{ <span class="keyword">return</span> simd_functions_invoker&lt;T,<span class="keyword">typename</span> simd_traits&lt;T&gt;::type&gt;::load_u(src); }

<span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="class">T</span>&gt; <span class="directive">inline</span> <span class="directive">void</span>
store_a(T* dst, <span class="directive">const</span> <span class="keyword">typename</span> simd_traits&lt;T&gt;::type&amp; src)
{ simd_functions_invoker&lt;T,<span class="keyword">typename</span> simd_traits&lt;T&gt;::type&gt;::store_a(dst,src); }

<span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="class">T</span>&gt; <span class="directive">inline</span> <span class="directive">void</span>
store_u(T* dst, <span class="directive">const</span> <span class="keyword">typename</span> simd_traits&lt;T&gt;::type&amp; src)
{ simd_functions_invoker&lt;T,<span class="keyword">typename</span> simd_traits&lt;T&gt;::type&gt;::store_u(dst,src); }
</pre></td>
</tr></table>
 </figure></notextile></div>

<p>Now we can use these generic functions in the previous loop so it works with any type, even those
which don’t support vectorization:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>sample.cpp </span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
<a href="#n7" name="n7">7</a>
<a href="#n8" name="n8">8</a>
<a href="#n9" name="n9">9</a>
<strong><a href="#n10" name="n10">10</a></strong>
<a href="#n11" name="n11">11</a>
<a href="#n12" name="n12">12</a>
<a href="#n13" name="n13">13</a>
<a href="#n14" name="n14">14</a>
<a href="#n15" name="n15">15</a>
<a href="#n16" name="n16">16</a>
<a href="#n17" name="n17">17</a>
</pre></td>
  <td class="code"><pre>
std::vector&lt;<span class="predefined-type">float</span>&gt; a,b,c,d,e;
<span class="comment">// ... resize a, b, c, d, and e so they hold n elements</span>
<span class="keyword">typedef</span> simd_traits&lt;<span class="predefined-type">float</span>&gt;::type vec_type;
size_t vec_size = simd_traits&lt;<span class="predefined-type">float</span>&gt;::size;
<span class="keyword">for</span>(size_t i = <span class="integer">0</span>; i &lt; n/vec_size; i += vec_size)
{
    vec_type av = load_a(&amp;a[i]);
    vec_type bv = load_a(&amp;b[i]);
    vec_type cv = load_a(&amp;c[i]);
    vec_type dv = load_a(&amp;d[i]);

    vec_type ev = av*bv + cv*dv;
    store_a(&amp;e[i],ev);
}
<span class="comment">// Remaining part of the loop</span>
<span class="comment">// ...</span>
</pre></td>
</tr></table>
 </figure></notextile></div>

<p>Or, if you want to be more concise:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>sample.cpp </span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
<a href="#n7" name="n7">7</a>
<a href="#n8" name="n8">8</a>
<a href="#n9" name="n9">9</a>
<strong><a href="#n10" name="n10">10</a></strong>
<a href="#n11" name="n11">11</a>
<a href="#n12" name="n12">12</a>
</pre></td>
  <td class="code"><pre>
std::vector&lt;<span class="predefined-type">float</span>&gt; a,b,c,d,e;
<span class="comment">// ... resize a, b, c, d, and e so they hold n elements</span>
<span class="keyword">typedef</span> simd_traits&lt;<span class="predefined-type">float</span>&gt;::type vec_type;
size_t vec_size = simd_traits&lt;<span class="predefined-type">float</span>&gt;::size;
<span class="keyword">for</span>(size_t i = <span class="integer">0</span>; i &lt; n/vec_size; i += vec_size)
{
    vec_type ev = load_a(&amp;a[i])*load_a(&amp;b[i]) + load_a(&amp;c[i])*load_a(&amp;d[i]));
    store_a(&amp;e[i], ev);
}
<span class="comment">// Remaining part of the loop</span>
<span class="comment">// ...</span>
</pre></td>
</tr></table>
 </figure></notextile></div>

<p>We’ve reached our goal, we can use intrinsics almost as we use float; in a real application code, it is likely
that you initialize the wrappers through load functions, then perform the computations and finally store the
results (like in the not concise version of the generic loop); thus the only difference between classical code
and code with SIMD wrappers is the initialization and storing of wrappers (and eventually the functions signatures
if you want to pass wrappers instead of scalars), the other parts should be exactly the same and the code remains
easy to read and to maintain.</p>

<h3 id="detecting-the-supported-instruction-set">4.3 Detecting the supported instruction set</h3>

<p><a name="detecting_instr_set"></a>Until now, we’ve assumed we were able to detect at compile time the available instruction set.
Let’s see now how to achieve this. Compilers often provide preprocessor tokens depending on the available instruction set, but
these tokens may vary from one compiler to another, so we have to standardize that. On most 64-bit compilers, the tokens look
like <strong>__SSE__</strong> or <strong>__SSE3__</strong>, on 32-bit systems, Microsoft compiler sets the preprocessor token <strong>_M_IX86_FP</strong> to
1 for SSE (vectorization of float) and 2 for SSE2 (vetorization of double and integers).</p>

<p>Here is how we can standardize that:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>simd_config.hpp </span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
<a href="#n7" name="n7">7</a>
<a href="#n8" name="n8">8</a>
<a href="#n9" name="n9">9</a>
<strong><a href="#n10" name="n10">10</a></strong>
<a href="#n11" name="n11">11</a>
<a href="#n12" name="n12">12</a>
<a href="#n13" name="n13">13</a>
<a href="#n14" name="n14">14</a>
<a href="#n15" name="n15">15</a>
<a href="#n16" name="n16">16</a>
<a href="#n17" name="n17">17</a>
<a href="#n18" name="n18">18</a>
<a href="#n19" name="n19">19</a>
<strong><a href="#n20" name="n20">20</a></strong>
<a href="#n21" name="n21">21</a>
<a href="#n22" name="n22">22</a>
<a href="#n23" name="n23">23</a>
<a href="#n24" name="n24">24</a>
<a href="#n25" name="n25">25</a>
<a href="#n26" name="n26">26</a>
<a href="#n27" name="n27">27</a>
<a href="#n28" name="n28">28</a>
<a href="#n29" name="n29">29</a>
<strong><a href="#n30" name="n30">30</a></strong>
</pre></td>
  <td class="code"><pre>
<span class="preprocessor">#if</span> (defined(_M_AMD64) || defined(_M_X64) || defined(__amd64)) &amp;&amp; ! defined(__x86_64__)
    <span class="preprocessor">#define</span> __x86_64__ <span class="integer">1</span>
<span class="preprocessor">#endif</span>

<span class="comment">// Find sse instruction set from compiler macros if SSE_INSTR_SET not defined</span>
<span class="comment">// Note: Not all compilers define these macros automatically</span>
<span class="preprocessor">#ifndef</span> SSE_INSTR_SET
    <span class="preprocessor">#if</span> defined ( __AVX2__ )
        <span class="preprocessor">#define</span> SSE_INSTR_SET <span class="integer">8</span>
    <span class="preprocessor">#elif</span> defined ( __AVX__ )
        <span class="preprocessor">#define</span> SSE_INSTR_SET <span class="integer">7</span>
    <span class="preprocessor">#elif</span> defined ( __SSE4_2__ )
        <span class="preprocessor">#define</span> SSE_INSTR_SET <span class="integer">6</span>
    <span class="preprocessor">#elif</span> defined ( __SSE4_1__ )
        <span class="preprocessor">#define</span> SSE_INSTR_SET <span class="integer">5</span>
    <span class="preprocessor">#elif</span> defined ( __SSSE3__ )
        <span class="preprocessor">#define</span> SSE_INSTR_SET <span class="integer">4</span>
    <span class="preprocessor">#elif</span> defined ( __SSE3__ )
        <span class="preprocessor">#define</span> SSE_INSTR_SET <span class="integer">3</span>
    <span class="preprocessor">#elif</span> defined ( __SSE2__ ) || defined ( __x86_64__ )
        <span class="preprocessor">#define</span> SSE_INSTR_SET <span class="integer">2</span>
    <span class="preprocessor">#elif</span> defined ( __SSE__ )
        <span class="preprocessor">#define</span> SSE_INSTR_SET <span class="integer">1</span>
    <span class="preprocessor">#elif</span> defined ( _M_IX86_FP )           <span class="comment">// Defined in MS compiler on 32bits system. 1: SSE, 2: SSE2</span>
        <span class="preprocessor">#define</span> SSE_INSTR_SET _M_IX86_FP
    <span class="preprocessor">#else</span>
        <span class="preprocessor">#define</span> SSE_INSTR_SET <span class="integer">0</span>
    <span class="preprocessor">#endif</span> <span class="comment">// instruction set defines</span>
<span class="preprocessor">#endif</span> <span class="comment">// SSE_INSTR_SET</span>
</pre></td>
</tr></table>
 </figure></notextile></div>

<p>Now we can use the <strong>SSE_INSTR_SET</strong> token to include the right file:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>simd_config.hpp </span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
<a href="#n7" name="n7">7</a>
<a href="#n8" name="n8">8</a>
<a href="#n9" name="n9">9</a>
<strong><a href="#n10" name="n10">10</a></strong>
<a href="#n11" name="n11">11</a>
<a href="#n12" name="n12">12</a>
<a href="#n13" name="n13">13</a>
<a href="#n14" name="n14">14</a>
<a href="#n15" name="n15">15</a>
<a href="#n16" name="n16">16</a>
<a href="#n17" name="n17">17</a>
<a href="#n18" name="n18">18</a>
<a href="#n19" name="n19">19</a>
<strong><a href="#n20" name="n20">20</a></strong>
<a href="#n21" name="n21">21</a>
<a href="#n22" name="n22">22</a>
<a href="#n23" name="n23">23</a>
<a href="#n24" name="n24">24</a>
</pre></td>
  <td class="code"><pre>
<span class="preprocessor">#</span><span class="comment">// Include the appropriate header file for intrinsic functions</span>
<span class="preprocessor">#if</span> SSE_INSTR_SET &gt; <span class="integer">7</span>                  <span class="comment">// AVX2 and later</span>
    <span class="preprocessor">#ifdef</span> __GNUC__
        <span class="preprocessor">#include</span> <span class="include">&lt;x86intrin.h&gt;</span>         <span class="comment">// x86intrin.h includes header files for whatever instruction</span>
                                       <span class="comment">// sets are specified on the compiler command line, such as:</span>
                                       <span class="comment">// xopintrin.h, fma4intrin.h</span>
    <span class="preprocessor">#else</span>
        <span class="preprocessor">#include</span> <span class="include">&lt;immintrin.h&gt;</span>         <span class="comment">// MS version of immintrin.h covers AVX, AVX2 and FMA3</span>
    <span class="preprocessor">#endif</span> <span class="comment">// __GNUC__</span>
<span class="preprocessor">#elif</span> SSE_INSTR_SET == <span class="integer">7</span>
    <span class="preprocessor">#include</span> <span class="include">&lt;immintrin.h&gt;</span>             <span class="comment">// AVX</span>
<span class="preprocessor">#elif</span> SSE_INSTR_SET == <span class="integer">6</span>
    <span class="preprocessor">#include</span> <span class="include">&lt;nmmintrin.h&gt;</span>             <span class="comment">// SSE4.2</span>
<span class="preprocessor">#elif</span> SSE_INSTR_SET == <span class="integer">5</span>
    <span class="preprocessor">#include</span> <span class="include">&lt;smmintrin.h&gt;</span>             <span class="comment">// SSE4.1</span>
<span class="preprocessor">#elif</span> SSE_INSTR_SET == <span class="integer">4</span>
    <span class="preprocessor">#include</span> <span class="include">&lt;tmmintrin.h&gt;</span>             <span class="comment">// SSSE3</span>
<span class="preprocessor">#elif</span> SSE_INSTR_SET == <span class="integer">3</span>
    <span class="preprocessor">#include</span> <span class="include">&lt;pmmintrin.h&gt;</span>             <span class="comment">// SSE3</span>
<span class="preprocessor">#elif</span> SSE_INSTR_SET == <span class="integer">2</span>
    <span class="preprocessor">#include</span> <span class="include">&lt;emmintrin.h&gt;</span>             <span class="comment">// SSE2</span>
<span class="preprocessor">#elif</span> SSE_INSTR_SET == <span class="integer">1</span>
    <span class="preprocessor">#include</span> <span class="include">&lt;xmmintrin.h&gt;</span>             <span class="comment">// SSE</span>
</pre></td>
</tr></table>
 </figure></notextile></div>

<p>Note that if you split the implementation of SSE wrappers and AVX wrappers into different files, you
can also use the <strong>SSE_INSTR_SET</strong> token to include the implementation file in the simd.hpp file:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>simd.hpp </span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
<a href="#n7" name="n7">7</a>
<a href="#n8" name="n8">8</a>
<a href="#n9" name="n9">9</a>
<strong><a href="#n10" name="n10">10</a></strong>
<a href="#n11" name="n11">11</a>
</pre></td>
  <td class="code"><pre>
<span class="preprocessor">#include</span> <span class="include">&quot;simd_config.hpp&quot;</span>
<span class="preprocessor">#if</span> SSE_INSTR_SET &gt; <span class="integer">6</span>
    <span class="preprocessor">#include</span> <span class="include">&quot;simd_avx.hpp&quot;</span>
<span class="preprocessor">#endif</span>
<span class="preprocessor">#if</span> SSE_INSTR_SET &gt; <span class="integer">0</span>
    <span class="preprocessor">#include</span> <span class="include">&quot;simd_sse.hpp&quot;</span>
<span class="preprocessor">#endif</span>

<span class="comment">// Definition of traits and generic load and store functions</span>
<span class="comment">// ...</span>
</pre></td>
</tr></table>
 </figure></notextile></div>

<p>Now from the client code, the only file to include is simd.hpp, and everything will be available.</p>

<h3 id="going-further">4.4 Going further</h3>

<p>Now that we have nice wrappers providing basic functionalities, what could be the next step ?
Well, first we could add a method to retrieve an element in the vector:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>simd_base.hpp </span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
<a href="#n7" name="n7">7</a>
<a href="#n8" name="n8">8</a>
<a href="#n9" name="n9">9</a>
<strong><a href="#n10" name="n10">10</a></strong>
<a href="#n11" name="n11">11</a>
<a href="#n12" name="n12">12</a>
<a href="#n13" name="n13">13</a>
<a href="#n14" name="n14">14</a>
<a href="#n15" name="n15">15</a>
<a href="#n16" name="n16">16</a>
<a href="#n17" name="n17">17</a>
<a href="#n18" name="n18">18</a>
</pre></td>
  <td class="code"><pre>
<span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="class">X</span>&gt;
    <span class="keyword">class</span> <span class="class">simd_vector</span>
    {
    <span class="directive">public</span>:

        <span class="keyword">typedef</span> simd_traits&lt;X&gt;::value_type value_type;

        <span class="comment">// ...</span>

        value_type <span class="directive">operator</span>[](size_t index) <span class="directive">const</span>
        {
            size_t size = simd_traits&lt;X&gt;::size;
            value_type v[size];
            (*<span class="local-variable">this</span>)().store_u(v);
            <span class="keyword">return</span> v[index];
        }
    };
</pre></td>
</tr></table>
 </figure></notextile></div>

<p>We can add horizontal add function, useful for linear algebra products:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>simd_sse.hpp</span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
<a href="#n7" name="n7">7</a>
<a href="#n8" name="n8">8</a>
<a href="#n9" name="n9">9</a>
<strong><a href="#n10" name="n10">10</a></strong>
<a href="#n11" name="n11">11</a>
<a href="#n12" name="n12">12</a>
</pre></td>
  <td class="code"><pre>
    <span class="directive">inline</span> <span class="predefined-type">float</span> hadd(<span class="directive">const</span> vector4f&amp; rhs)
    {
    <span class="preprocessor">#if</span> SSE_INSTR_SET &gt;= <span class="integer">3</span> <span class="comment">// SSE3</span>
        __m128 tmp0 = _mm_hadd_ps(rhs,rhs);
        __m128 tmp1 = _mm_hadd_ps(tmp0,tmp0);
    <span class="preprocessor">#else</span>
        __m128 tmp0 = _mm_add_ps(rhs,_mm_movehl_ps(rhs,rhs));
        __m128 tmp1 = _mm_add_ss(tmp0,_mm_shuffle_ps(tmp0,tmp0,<span class="integer">1</span>));
    <span class="preprocessor">#endif</span>
        <span class="keyword">return</span> _mm_cvtss_f32(tmp1);
    }
</pre></td>
</tr></table>
 </figure></notextile></div>

<p>Another useful project would be to write overloads of standard mathematical functions (exp, log, etc) that work
with the wrappers.</p>

<p>As you can see, writing the wrappers is just the beginning, you can then enrich them with whatever functionality
you need but this goes beyond the topic of this first series of articles.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Writing C++ Wrappers for SIMD Intrinsics (4)]]></title>
    <link href="http://jmabille.github.io/blog/2014/10/13/writing-c-plus-plus-wrappers-for-simd-intrinsics-4/"/>
    <updated>2014-10-13T22:46:01+02:00</updated>
    <id>http://jmabille.github.io/blog/2014/10/13/writing-c-plus-plus-wrappers-for-simd-intrinsics-4</id>
    <content type="html"><![CDATA[<h2 id="plugging-the-wrappers-into-existing-code">3. Plugging the wrappers into existing code</h2>

<h3 id="storing-vector4f-instead-of-float">3.1 Storing vector4f instead of float</h3>

<p>Now we have nice wrappers, let’s see how we can use them in real code. Suppose you have the following
computation loop:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>sample.cpp </span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
<a href="#n7" name="n7">7</a>
<a href="#n8" name="n8">8</a>
<a href="#n9" name="n9">9</a>
</pre></td>
  <td class="code"><pre>
std::vector&lt;<span class="predefined-type">float</span>&gt; a, b, c, d, e;
<span class="comment">// somewhere in the code, a, b, c, d and e are</span>
<span class="comment">// resized so they hold n elements</span>
<span class="comment">// ...</span>
<span class="keyword">for</span>(size_t i = <span class="integer">0</span>; i &lt; n; ++i)
{
    e[i] = a[i]*b[i] + c[i]*d[i];
}
</pre></td>
</tr></table>
 </figure></notextile></div>

<!-- more -->

<p>A first solution could be to store vector of vector4f instead of vector of float:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>sample.cpp </span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
<a href="#n7" name="n7">7</a>
<a href="#n8" name="n8">8</a>
<a href="#n9" name="n9">9</a>
</pre></td>
  <td class="code"><pre>
std::vector&lt;vector4f&gt; a, b ,c, d, e;
<span class="comment">// somewhere in the code, a, b, c, d and e are</span>
<span class="comment">// resized so they hold n/4 vector4f</span>
<span class="comment">// ...</span>
<span class="keyword">for</span>(size_t i = <span class="integer">0</span>; i &lt; n/<span class="integer">4</span>; ++i)
{
    e[i] = a[i]*b[i] + c[i]*d[i];
}
</pre></td>
</tr></table>
 </figure></notextile></div>

<p>Not so bad, thanks to the operators overloads, the code is exactly the same as the one for float, but
the operations are performed on four floats at once. If n is not a multiple of four, we allocate an
additional vector4f in each vector and we initialize the useless elements with 0.</p>

<p>The problem is you could need to work with the scalar instead of the vector4f, for instance if you search
for a specific element in the vector or if you fill your vector pushing back elements one by one. In this
case, you would have to recode any piece of algorithm that works on single elements (and that includes a
lot of STL algorithms) and then add special code for working on scalars within a vector4f. Working on
scalars within vector4f is possible (we’ll see later how to modify our wrappers so we can do ir), but is
slower than working directly on scalars, thus you could lose the benefits of using vectorization.</p>

<h3 id="initializing-vector4f-from-container-of-float">3.2 Initializing vector4f from container of float</h3>

<p>Another solution could be to initialize the wrapper from values stored in a vector:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>sample.cpp </span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
<a href="#n7" name="n7">7</a>
<a href="#n8" name="n8">8</a>
<a href="#n9" name="n9">9</a>
<strong><a href="#n10" name="n10">10</a></strong>
<a href="#n11" name="n11">11</a>
<a href="#n12" name="n12">12</a>
<a href="#n13" name="n13">13</a>
<a href="#n14" name="n14">14</a>
<a href="#n15" name="n15">15</a>
<a href="#n16" name="n16">16</a>
<a href="#n17" name="n17">17</a>
<a href="#n18" name="n18">18</a>
<a href="#n19" name="n19">19</a>
</pre></td>
  <td class="code"><pre>
std::vector&lt;<span class="predefined-type">float</span>&gt;a, b, c, d, e;
<span class="comment">// somewhere in the code, a, b, c, d and e are</span>
<span class="comment">// resized so they hold n elements</span>
/ ...
<span class="keyword">for</span>(size_t i = <span class="integer">0</span>; i &lt; n/<span class="integer">4</span>; i += <span class="integer">4</span>)
{
    vector4f av(a[i],a[i+<span class="integer">1</span>],a[i+<span class="integer">2</span>],a[i+<span class="integer">3</span>]);
    vector4f bv(b[i],b[i+<span class="integer">1</span>],b[i+<span class="integer">2</span>],b[i+<span class="integer">3</span>]);
    vector4f cv(c[i],c[i+<span class="integer">1</span>],c[i+<span class="integer">2</span>],c[i+<span class="integer">3</span>]);
    vector4f dv(d[i],d[i+<span class="integer">1</span>],d[i+<span class="integer">2</span>],d[i+<span class="integer">3</span>]);

    vector4f ev = av*bv + cv*dv;
    <span class="comment">// how do we store ev in e[i],e[i+1],e[i+2],e[i+3] ?</span>
}
<span class="keyword">for</span>(size_t i = n/<span class="integer">4</span>; i &lt; n; ++i)
{
    e[i] = a[i]*b[i] + c[i]*d[i];
}
</pre></td>
</tr></table>
 </figure></notextile></div>

<p>The first problem is that we need a way to store a vector4f into 4 floats; as said in the previous paragraph, we
can add to our wrappers a method that returns a scalar within the vector4f and invoke it that way:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>sample.cpp </span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
</pre></td>
  <td class="code"><pre>
e[i]   = ev[<span class="integer">0</span>];
e[i+<span class="integer">1</span>] = ev[<span class="integer">1</span>];
e[i+<span class="integer">2</span>] = ev[<span class="integer">2</span>];
e[i+<span class="integer">3</span>] = ev[<span class="integer">3</span>];
</pre></td>
</tr></table>
 </figure></notextile></div>

<p>The second problem is that this code is not generic; if you migrate from SSE to AVX, you’ll have to update the
initialization of your wrapper so it takes 8 floats; the same for storing your vector4f in scalar results.</p>

<p>What we need here is a way to load float into vector4f and to store vector4f into floats that doesn’t
depend on the size of vector4f (that is, 4). That’s the aim of the load and store intrinsics.</p>

<h3 id="load-from-and-store-to-memory">3.3 Load from and store to memory</h3>

<p>If you take a look at the xmmintrin.h file, you’ll notice the compiler provides two kinds of load and store
intrinsics:</p>

<ul>
  <li>_mm_load_ps / _mm_store_ps: these functions require the source / destination memory buffer to be aligned;
the alignment boundary depends on the version of the SIMD you’re using: 16 bits for SSE2, 32 bits for AVX.</li>
  <li>_mm_loadu_ps / _mm_storeu_ps: these functions don’t require any alignment of the source / destination
memory buffer.</li>
</ul>

<p>Intrinsics with alignment constraints are faster, and should be used by default; however, even if memory allocations
are aligned, you can’t guarantee that the memory buffer you pass to the load / store function is aligned. Indeed,
consider the matrix product C=AxB, where A is a 15x15 matrix of floats with linear row storage and B a vector that
holds 15 float elements. The computation of C[1] starts with:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>sample.cpp </span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
<a href="#n7" name="n7">7</a>
</pre></td>
  <td class="code"><pre>
vector4f tmp(<span class="integer">0</span>);
<span class="keyword">for</span>(size_t k = <span class="integer">0</span>; k &lt; <span class="integer">12</span>; k+=<span class="integer">4</span>)
{
    tmp += loadu(a+<span class="integer">15</span>+k) * load(b+k);
}
<span class="comment">// ...</span>
</pre></td>
</tr></table>
 </figure></notextile></div>

<p>Here, if A is 16-byte aligned, since the size of a float is 4 bytes, a[15], a[19] and a[23] aren’t 16-byte aligned, and you
have to use the unaligned overload of the intrinsics (designated by the generic <em>loadu</em> function in the sample code).</p>

<p>Here’s how we need to update our wrappers to handle load and store functions:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>simd_sse.hpp </span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
<a href="#n7" name="n7">7</a>
<a href="#n8" name="n8">8</a>
<a href="#n9" name="n9">9</a>
<strong><a href="#n10" name="n10">10</a></strong>
<a href="#n11" name="n11">11</a>
<a href="#n12" name="n12">12</a>
<a href="#n13" name="n13">13</a>
<a href="#n14" name="n14">14</a>
<a href="#n15" name="n15">15</a>
<a href="#n16" name="n16">16</a>
<a href="#n17" name="n17">17</a>
<a href="#n18" name="n18">18</a>
<a href="#n19" name="n19">19</a>
<strong><a href="#n20" name="n20">20</a></strong>
<a href="#n21" name="n21">21</a>
<a href="#n22" name="n22">22</a>
<a href="#n23" name="n23">23</a>
<a href="#n24" name="n24">24</a>
<a href="#n25" name="n25">25</a>
<a href="#n26" name="n26">26</a>
<a href="#n27" name="n27">27</a>
<a href="#n28" name="n28">28</a>
<a href="#n29" name="n29">29</a>
</pre></td>
  <td class="code"><pre>
<span class="keyword">class</span> <span class="class">vector4f</span> : <span class="directive">public</span> simd_vector&lt;vector4f&gt;
{
<span class="directive">public</span>:

    <span class="comment">// ...</span>

    <span class="directive">inline</span> vector4f&amp; load_a(<span class="directive">const</span> <span class="predefined-type">float</span>* src)
    {
        m_value = _mm_load_ps(src);
        <span class="keyword">return</span> *<span class="local-variable">this</span>;
    }

    <span class="directive">inline</span> vector4f&amp; load_u(<span class="directive">const</span> <span class="predefined-type">float</span>* src)
    {
        m_value = _mm_loadu_ps(src);
        <span class="keyword">return</span> *<span class="local-variable">this</span>;
    }

    <span class="directive">inline</span> <span class="directive">void</span> store_a(<span class="predefined-type">float</span>* dst) <span class="directive">const</span>
    {
        _mm_store_ps(dst,m_value);
    }

    <span class="directive">inline</span> <span class="directive">void</span> store_u(<span class="predefined-type">float</span>* dst) <span class="directive">const</span>
    {
        _mm_storeu_ps(dst,m_value);
    }
};
</pre></td>
</tr></table>
 </figure></notextile></div>

<p>Assuming the memory buffer of std::vector is 16-bytes aligned, the sample code becomes:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>sample.cpp </span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
<a href="#n7" name="n7">7</a>
<a href="#n8" name="n8">8</a>
<a href="#n9" name="n9">9</a>
<strong><a href="#n10" name="n10">10</a></strong>
<a href="#n11" name="n11">11</a>
<a href="#n12" name="n12">12</a>
<a href="#n13" name="n13">13</a>
<a href="#n14" name="n14">14</a>
<a href="#n15" name="n15">15</a>
<a href="#n16" name="n16">16</a>
<a href="#n17" name="n17">17</a>
<a href="#n18" name="n18">18</a>
<a href="#n19" name="n19">19</a>
</pre></td>
  <td class="code"><pre>
std::vector&lt;<span class="predefined-type">float</span>&gt;a, b, c, d, e;
<span class="comment">// somewhere in the code, a, b, c, d and e are</span>
<span class="comment">// resized so they hold n elements</span>
/ ...
<span class="keyword">for</span>(size_t i = <span class="integer">0</span>; i &lt; n/<span class="integer">4</span>; i += <span class="integer">4</span>)
{
    vector4f av; av.load_a(&amp;a[i]);
    vector4f bv; bv.load_a(&amp;b[i));
    vector4f cv; cv.load_a(&amp;c[i]);
    vector4f dv; dv.load_a(&amp;d[i]);

    vector4f ev = av*bv + cv*dv;
    ev.store_a(&amp;e[i]);
}
<span class="keyword">for</span>(size_t i = n/<span class="integer">4</span>; i &lt; n; ++i)
{
    e[i] = a[i]*b[i] + c[i]*d[i];
}
</pre></td>
</tr></table>
 </figure></notextile></div>

<p>Now, if we migrate our code from SSE to AVX, all we have to do is to replace vector4f by vector8f! (Ok, we also have to deal
with memory alignment issues, I come back to this in a few moments). We’ll see in a future section how we can avoid the explicit
usage of vector4f so we get full genericity. But for now, we have to face a last problem: in the sample code, we assumed the
memory buffer wrapped by std::vector was 16-bytes aligned. <a name="simd_memory_allocator"></a>How do we know a memory allocation
is aligned, and how do we know the boundary alignment?</p>

<p>The answer is that it depends on your system and your compiler. On Windows 64 bits, dynamic memory allocation is 16-bytes aligned;
in GNU systems, a block returned by malloc or realloc is always a multiple of 8 (32-bit systems) or 16 (64-bit system). So if we
want to write code generic enough to handle many SIMD instruction set, it’s clear we must provide a way to ensure memory allocation
is always aligned, and is aligned on a given boundary.</p>

<p>The solution is to design an aligned memory allocator and to use it in std::vector:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>sample.cpp </span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
</pre></td>
  <td class="code"><pre>
<span class="keyword">typedef</span> aligned_allocator&lt;<span class="integer">16</span>&gt; simd_allocator;
std::vector&lt;<span class="predefined-type">float</span>,simd_allocator&gt; a,b,c,d,e.
<span class="comment">// ....</span>
</pre></td>
</tr></table>
 </figure></notextile></div>

<p>Now, we can handle any alignment boundary requirement through a typedef:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>sample.cpp </span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
</pre></td>
  <td class="code"><pre>
<span class="keyword">typedef</span> aligned_allocator&lt;<span class="integer">16</span>&gt; simd_allocator_sse; <span class="comment">// SSE</span>
<span class="keyword">typedef</span> aligned_allocator&lt;<span class="integer">32</span>&gt; simd_allocator_avx; <span class="comment">// AVX </span>
</pre></td>
</tr></table>
 </figure></notextile></div>

<h3 id="conditional-branch">3.4 Conditional branch</h3>

<p>Another issue we have to deal with, when we plug our wrapper, is conditional branching: indeed the if-else statement evaluates
a branch depending on the scalar condition, but the if statement works only for scalar condition, and we can’t directly override
it so it works with our wrappers. Consider the following code:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>sample.cpp </span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
<a href="#n7" name="n7">7</a>
<a href="#n8" name="n8">8</a>
<a href="#n9" name="n9">9</a>
<strong><a href="#n10" name="n10">10</a></strong>
<a href="#n11" name="n11">11</a>
<a href="#n12" name="n12">12</a>
<a href="#n13" name="n13">13</a>
<a href="#n14" name="n14">14</a>
</pre></td>
  <td class="code"><pre>
std::vector&lt;<span class="predefined-type">float</span>&gt; a,b,c,d,e;
<span class="comment">// ... initialization of a, b, c and d</span>
<span class="keyword">for</span>(size_t i = <span class="integer">0</span>; i &lt; a.size(); ++i)
{
    <span class="keyword">if</span>(a[i] &gt; <span class="integer">0</span>)
    {
        e[i] = a[i]*b[i] + c[i]*d[i];
    }
    <span class="keyword">else</span>
    {
        e[i] = b[i] + c[i]*d[i];
    }
}
</pre></td>
</tr></table>
 </figure></notextile></div>

<p>What we do here is selecting a value for e[i] depending on the sign of a[i]; the code could be written in a suboptimal way:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>sample.cpp </span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
<a href="#n7" name="n7">7</a>
<a href="#n8" name="n8">8</a>
<a href="#n9" name="n9">9</a>
<strong><a href="#n10" name="n10">10</a></strong>
<a href="#n11" name="n11">11</a>
<a href="#n12" name="n12">12</a>
<a href="#n13" name="n13">13</a>
</pre></td>
  <td class="code"><pre>
<span class="predefined-type">float</span> select(<span class="predefined-type">bool</span> cond, <span class="predefined-type">float</span> v1, <span class="predefined-type">float</span> v2)
{
    <span class="keyword">return</span> cond ? v1 : v2;
}

<span class="keyword">for</span>(size_t i = <span class="integer">0</span>; i &lt; a.size(); ++i)
{
    <span class="predefined-type">float</span> e_tmp1 = a[i]*b[i] + c[i]*d[i];
    <span class="predefined-type">float</span> e_tmp2 = b[i] + c[i]*d[i];

    e[i] = select(a[i] &gt; <span class="integer">0</span>, e_tmp1, e_tmp2);
}
</pre></td>
</tr></table>
 </figure></notextile></div>

<p>Even though the “select” function is a bit overkill in the scalar case, it is exactly what we need for handling conditional
branching with the SIMD wrappers. This means the two values (or “branches”) of the conditional statement will be evaluated
before we choose the one to affect, but we can’t do better. And since you execute your conditional statement on 4 floats
at once, it is still faster than the scalar version, even if suboptimal. The only case where the vectorized code could
have a performance loss compared to the scalar code is if one of the conditional branch takes much more time to compute than
the other and its result is seldom used.</p>

<p>Knowing this, let’s see how we can implement a select function taking SIMD wrapper parameters. Depending on the SSE version,
the compiler may provide a built-in function we can directly use as ternary operator. If not, we have to handle it with old
bitwise logical:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>sample.cpp </span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
<a href="#n7" name="n7">7</a>
<a href="#n8" name="n8">8</a>
<a href="#n9" name="n9">9</a>
<strong><a href="#n10" name="n10">10</a></strong>
</pre></td>
  <td class="code"><pre>
vector4f select(<span class="directive">const</span> vector4fb&amp; cond, <span class="directive">const</span> vector4f&amp; a, <span class="directive">const</span> vector4f&amp; b)
{
<span class="comment">// Don't bother with the SSE_INSTR_SET preprocessor token, we'll be back ont it later</span>
<span class="preprocessor">#if</span> SSE_INSTR_SET &gt;= <span class="integer">5</span> <span class="comment">// SSE 4.1</span>
    <span class="keyword">return</span> _mm_blendv_ps(b,a,cond);
<span class="preprocessor">#else</span>
    <span class="keyword">return</span> _mm_or_ps(_mm_and_ps(cond,a),_mm_andnot_ps(cond,b));
<span class="preprocessor">#endif</span>
}
</pre></td>
</tr></table>
 </figure></notextile></div>

<p>That’s it! We can now write the previous loop using full vectorization:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>sample.cpp </span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
<a href="#n7" name="n7">7</a>
<a href="#n8" name="n8">8</a>
<a href="#n9" name="n9">9</a>
<strong><a href="#n10" name="n10">10</a></strong>
<a href="#n11" name="n11">11</a>
<a href="#n12" name="n12">12</a>
<a href="#n13" name="n13">13</a>
<a href="#n14" name="n14">14</a>
<a href="#n15" name="n15">15</a>
<a href="#n16" name="n16">16</a>
</pre></td>
  <td class="code"><pre>
<span class="keyword">for</span>(size_t i = <span class="integer">0</span>; i &lt; n/<span class="integer">4</span>; i+=<span class="integer">4</span>)
{
    vector4f av; av.load_a(&amp;a[i]);
    vector4f bv; bv.load_a(&amp;b[i));
    vector4f cv; cv.load_a(&amp;c[i]);
    vector4f dv; dv.load_a(&amp;d[i]);

    vector4f e_tmp1 = av*bv + cv*dv;
    vector4f e_tmp2 = bv + cv*dv;

    vector4f ev = select(av &gt; <span class="integer">0</span>, e_tmp1, e_tmp2);
    ev.store_a(&amp;e[i]);
}
<span class="comment">// scalar version for the last elements of the vectors</span>
<span class="comment">// ...</span>
</pre></td>
</tr></table>
 </figure></notextile></div>

<p>Although this code is far better than using intrinsics directly, it is still very verbose and, worse, not generic. If you want to update
your code to take advantage of AVX instead of SSE, you need to replace every occurence of vector4f by vector8f, and to change the loop
condition and increment so it takes into account the size of vector8f. Doing this in real code will quickly become painful.</p>

<p>What we need here is full genericity, so that replacing an instruction set by another requires almost no code change. That the point of
the next section.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Writing C++ Wrappers for SIMD Intrinsics (3)]]></title>
    <link href="http://jmabille.github.io/blog/2014/10/10/writing-c-plus-plus-wrappers-for-simd-intrinsics-3/"/>
    <updated>2014-10-10T02:35:03+02:00</updated>
    <id>http://jmabille.github.io/blog/2014/10/10/writing-c-plus-plus-wrappers-for-simd-intrinsics-3</id>
    <content type="html"><![CDATA[<h2 id="a-namesection2a2-first-version-of-wrappers"><a name="section_2"></a>2. First version of wrappers</h2>

<p>Now that we know a little more about SSE and AVX, let’s write some  code; the wrappers will have
a data vector member and provide arithmetic, comparison and logical operators overloads. Throughout
this section, I will mainly focus on vector4f, the wrapper around __m128, but translating the code
for other data vectors should not be difficult thanks to the previous section. Since the wrappers will
be used as numerical types, they must have value semantics, that is they must define copy constructor,
assignment operator and non-virtual destructor.</p>

<!-- more -->

<h3 id="initialization-and-assignment">2.1 Initialization and assignment</h3>

<p>SSE and AVX data vectors can be initialized from different inputs: a single value for all elements,
a value per element, or another data vector.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>simd_sse.hpp </span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
<a href="#n7" name="n7">7</a>
<a href="#n8" name="n8">8</a>
<a href="#n9" name="n9">9</a>
<strong><a href="#n10" name="n10">10</a></strong>
<a href="#n11" name="n11">11</a>
<a href="#n12" name="n12">12</a>
<a href="#n13" name="n13">13</a>
<a href="#n14" name="n14">14</a>
<a href="#n15" name="n15">15</a>
<a href="#n16" name="n16">16</a>
<a href="#n17" name="n17">17</a>
<a href="#n18" name="n18">18</a>
<a href="#n19" name="n19">19</a>
<strong><a href="#n20" name="n20">20</a></strong>
<a href="#n21" name="n21">21</a>
<a href="#n22" name="n22">22</a>
<a href="#n23" name="n23">23</a>
<a href="#n24" name="n24">24</a>
<a href="#n25" name="n25">25</a>
<a href="#n26" name="n26">26</a>
<a href="#n27" name="n27">27</a>
<a href="#n28" name="n28">28</a>
</pre></td>
  <td class="code"><pre>
<span class="keyword">class</span> <span class="class">vector4f</span>
{
<span class="directive">public</span>:

    <span class="directive">inline</span> vector4f() {}
    <span class="directive">inline</span> vector4f(<span class="predefined-type">float</span> f) : m_value(_mm_set1_ps(f)) {}
    <span class="directive">inline</span> vector4f(<span class="predefined-type">float</span> f0, <span class="predefined-type">float</span> f1, <span class="predefined-type">float</span> f2, <span class="predefined-type">float</span> f3) : m_value(_mm_setr_ps(f0,f1,f2,f3)) {}
    <span class="directive">inline</span> vector4f(<span class="directive">const</span> __m128&amp; rhs) : m_value(rhs) {}

    <span class="directive">inline</span> vector4f&amp; <span class="directive">operator</span>=(<span class="directive">const</span> __m128&amp; rhs)
    {
        m_value = rhs;
        <span class="keyword">return</span> *<span class="local-variable">this</span>;
    }

    <span class="directive">inline</span> vector4f(<span class="directive">const</span> vector4f&amp; rhs) : m_value(rhs.m_value) {}

    <span class="directive">inline</span> vector4f&amp; <span class="directive">operator</span>=(<span class="directive">const</span> vector4f&amp; rhs)
    {
        m_value = rhs.m_value;
        <span class="keyword">return</span> *<span class="local-variable">this</span>;
    }

<span class="directive">private</span>:

    __m128 m_value;
};
</pre></td>
</tr></table>
 </figure></notextile></div>

<h3 id="implicit-conversion">2.2 Implicit conversion</h3>

<p>The operators overloads have to access the m_value member of the wrapper so they can pass it as an argument to the intrinsic
functions:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>overload sample</span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
</pre></td>
  <td class="code"><pre>
vector4f <span class="directive">operator</span>+(<span class="directive">const</span> vector4f&amp; lhs, <span class="directive">const</span> vector4f&amp; rhs)
{
    <span class="keyword">return</span> _mm_add_ps(lhs.m_value,rhs.m_value);
}
</pre></td>
</tr></table>
 </figure></notextile></div>

<p>We could declare the operator overloads as friend functions of the wrapper class, or provide a get method returning the internal
m_value. Both of these solutions work, but aren’t elegant: the first requires a huge amount of friend declarations, the second
produces heavy code unpleasant to read.</p>

<p>A more elegant solution is to provide a conversion operator from vector4f to __m128; since vector4f can be implicitly converted
from __m128, we can now use vector4f or __m128 indifferently. Moreover we can save the vector4f copy constructor and assignment
operator:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>simd_sse.hpp </span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
<a href="#n7" name="n7">7</a>
<a href="#n8" name="n8">8</a>
<a href="#n9" name="n9">9</a>
<strong><a href="#n10" name="n10">10</a></strong>
<a href="#n11" name="n11">11</a>
<a href="#n12" name="n12">12</a>
<a href="#n13" name="n13">13</a>
<a href="#n14" name="n14">14</a>
<a href="#n15" name="n15">15</a>
<a href="#n16" name="n16">16</a>
<a href="#n17" name="n17">17</a>
<a href="#n18" name="n18">18</a>
<a href="#n19" name="n19">19</a>
<strong><a href="#n20" name="n20">20</a></strong>
<a href="#n21" name="n21">21</a>
<a href="#n22" name="n22">22</a>
<a href="#n23" name="n23">23</a>
<a href="#n24" name="n24">24</a>
<a href="#n25" name="n25">25</a>
<a href="#n26" name="n26">26</a>
</pre></td>
  <td class="code"><pre>
<span class="keyword">class</span> <span class="class">vector4f</span>
{
<span class="directive">public</span>:

    <span class="directive">inline</span> vector4f() {}
    <span class="directive">inline</span> vector4f(<span class="predefined-type">float</span> f) : m_value(_mm_set1_ps(f)) {}
    <span class="directive">inline</span> vector4f(<span class="predefined-type">float</span> f0, <span class="predefined-type">float</span> f1, <span class="predefined-type">float</span> f2, <span class="predefined-type">float</span> f3) : m_value(_mm_setr_ps(f0,f1,f2,f3)) {}
    <span class="directive">inline</span> vector4f(<span class="directive">const</span> __m128&amp; rhs) : m_value(rhs) {}

    <span class="directive">inline</span> vector4f&amp; <span class="directive">operator</span>=(<span class="directive">const</span> __m128&amp; rhs)
    {
        m_value = rhs;
        <span class="keyword">return</span> *<span class="local-variable">this</span>;
    }

    <span class="directive">inline</span> <span class="directive">operator</span> __m128() <span class="directive">const</span> { <span class="keyword">return</span> m_value; }

    <span class="comment">// vector4f(const vector4f&amp;) and operator=(const vector4f&amp;) are not required anymore:</span>
    <span class="comment">// the conversion operator will be called before calling vector4f(const __m128&amp;)</span>
    <span class="comment">// or operator=(const __m128&amp;)</span>

<span class="directive">private</span>:

    __m128 m_value;
};
</pre></td>
</tr></table>
 </figure></notextile></div>

<h3 id="arithmetic-operators-overloads">2.3 Arithmetic operators overloads</h3>

<p>Next step is to write the arithmetic operators overloads. The classic way to do this is to write
computed assignment operators and to use them in operators overloads, so they don’t have to access
private members of vector4f; but since vector4f can be implicitly converted to __m128, we can
do the opposite and avoid using a temporary (this won’t have any impact on performance since
the compiler can optimize it, but produces shorter and more pleasant code to read):</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>simd_sse.hpp </span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
<a href="#n7" name="n7">7</a>
<a href="#n8" name="n8">8</a>
<a href="#n9" name="n9">9</a>
<strong><a href="#n10" name="n10">10</a></strong>
<a href="#n11" name="n11">11</a>
<a href="#n12" name="n12">12</a>
<a href="#n13" name="n13">13</a>
<a href="#n14" name="n14">14</a>
<a href="#n15" name="n15">15</a>
<a href="#n16" name="n16">16</a>
<a href="#n17" name="n17">17</a>
<a href="#n18" name="n18">18</a>
</pre></td>
  <td class="code"><pre>
<span class="keyword">class</span> <span class="class">vector4f</span>
{
<span class="directive">public</span>:

    <span class="comment">// ...</span>

    <span class="directive">inline</span> vector4f&amp; <span class="directive">operator</span>+=(<span class="directive">const</span> vector4f&amp; rhs)
    {
        *<span class="local-variable">this</span> = *<span class="local-variable">this</span> + rhs;
        <span class="keyword">return</span> *<span class="local-variable">this</span>;
    }
};

<span class="directive">inline</span> vector4f <span class="directive">operator</span>+(<span class="directive">const</span> vector4f&amp; lhs, <span class="directive">const</span> vector4f&amp; rhs)
{
    <span class="keyword">return</span> _mm_add_ps(lhs,rhs);
}
</pre></td>
</tr></table>
 </figure></notextile></div>

<h3 id="the-need-for-a-base-class">2.4 The need for a base class</h3>

<p>We could go ahead and write the remaining arithmetic operators overloads, just as we did before:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>simd_sse.hpp </span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
<a href="#n7" name="n7">7</a>
<a href="#n8" name="n8">8</a>
<a href="#n9" name="n9">9</a>
<strong><a href="#n10" name="n10">10</a></strong>
<a href="#n11" name="n11">11</a>
<a href="#n12" name="n12">12</a>
<a href="#n13" name="n13">13</a>
<a href="#n14" name="n14">14</a>
<a href="#n15" name="n15">15</a>
<a href="#n16" name="n16">16</a>
</pre></td>
  <td class="code"><pre>
vector4f <span class="directive">operator</span>+(<span class="directive">const</span> vector4f&amp;, <span class="directive">const</span> vector4f&amp;);
<span class="comment">// Adds the same float value to each data vector member</span>
vector4f <span class="directive">operator</span>+(<span class="directive">const</span> vector4f&amp;, <span class="directive">const</span> <span class="predefined-type">float</span>&amp;);
vector4f <span class="directive">operator</span>+(<span class="directive">const</span> <span class="predefined-type">float</span>&amp;, <span class="directive">const</span> vector4f&amp;);

<span class="comment">// Similar for operator-, operator* and operator/</span>
<span class="comment">// ...</span>

vector4f <span class="directive">operator</span>-(<span class="directive">const</span> vector4f&amp;);

vector4f&amp; <span class="directive">operator</span>++();
vector4f <span class="directive">operator</span>++(<span class="predefined-type">int</span>);

<span class="comment">// Similar for operator--</span>
<span class="comment">// ...</span>
</pre></td>
</tr></table>
 </figure></notextile></div>

<p>But wait! Whenever you add a new wrapper, you’ll have to write these operators overloads again. Besides
the fact that you will need to type a lot of boilerplate code, computed assignment operators will be the
same as those of vector4f (that is, invoke the corresponding operator overload and return the object),
and even some operators overloads will have the same code as the one of vector4f operators. Code duplication
is never good, and we should look for ways to avoid it.</p>

<p>If we had encountered this problem for classes with entity semantics, we would have captured the common code
into a base class, and delegate the specific behavior to virtual methods, a typical use of classical dynamic
polymorphism. What we need here is an equivalent architecture for classes with value semantics and no virtual
methods (since virtual assignment operators are nonsense). This equivalent architecture is the CRTP
(Curiously Recurring Template Pattern). A lot has been written about CRTP and I will not dwell on it. If you
don’t know about this pattern, the most important thing to know is CRTP allows you to invoke methods of inheriting
classes from the base class just as you would do through virtual methods, except the target methods are resolved
at compile time.</p>

<p>Let’s call our base class simd_vector, it will be used as base class for every wrapper; here is what it should
look like:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>simd_base.hpp</span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
<a href="#n7" name="n7">7</a>
<a href="#n8" name="n8">8</a>
<a href="#n9" name="n9">9</a>
<strong><a href="#n10" name="n10">10</a></strong>
<a href="#n11" name="n11">11</a>
<a href="#n12" name="n12">12</a>
<a href="#n13" name="n13">13</a>
<a href="#n14" name="n14">14</a>
<a href="#n15" name="n15">15</a>
<a href="#n16" name="n16">16</a>
<a href="#n17" name="n17">17</a>
<a href="#n18" name="n18">18</a>
<a href="#n19" name="n19">19</a>
<strong><a href="#n20" name="n20">20</a></strong>
<a href="#n21" name="n21">21</a>
<a href="#n22" name="n22">22</a>
<a href="#n23" name="n23">23</a>
<a href="#n24" name="n24">24</a>
<a href="#n25" name="n25">25</a>
<a href="#n26" name="n26">26</a>
<a href="#n27" name="n27">27</a>
<a href="#n28" name="n28">28</a>
<a href="#n29" name="n29">29</a>
<strong><a href="#n30" name="n30">30</a></strong>
<a href="#n31" name="n31">31</a>
<a href="#n32" name="n32">32</a>
<a href="#n33" name="n33">33</a>
<a href="#n34" name="n34">34</a>
<a href="#n35" name="n35">35</a>
<a href="#n36" name="n36">36</a>
<a href="#n37" name="n37">37</a>
<a href="#n38" name="n38">38</a>
<a href="#n39" name="n39">39</a>
<strong><a href="#n40" name="n40">40</a></strong>
<a href="#n41" name="n41">41</a>
<a href="#n42" name="n42">42</a>
<a href="#n43" name="n43">43</a>
<a href="#n44" name="n44">44</a>
<a href="#n45" name="n45">45</a>
<a href="#n46" name="n46">46</a>
<a href="#n47" name="n47">47</a>
<a href="#n48" name="n48">48</a>
<a href="#n49" name="n49">49</a>
<strong><a href="#n50" name="n50">50</a></strong>
<a href="#n51" name="n51">51</a>
<a href="#n52" name="n52">52</a>
<a href="#n53" name="n53">53</a>
<a href="#n54" name="n54">54</a>
<a href="#n55" name="n55">55</a>
<a href="#n56" name="n56">56</a>
<a href="#n57" name="n57">57</a>
<a href="#n58" name="n58">58</a>
<a href="#n59" name="n59">59</a>
<strong><a href="#n60" name="n60">60</a></strong>
<a href="#n61" name="n61">61</a>
<a href="#n62" name="n62">62</a>
<a href="#n63" name="n63">63</a>
<a href="#n64" name="n64">64</a>
<a href="#n65" name="n65">65</a>
<a href="#n66" name="n66">66</a>
<a href="#n67" name="n67">67</a>
<a href="#n68" name="n68">68</a>
<a href="#n69" name="n69">69</a>
<strong><a href="#n70" name="n70">70</a></strong>
<a href="#n71" name="n71">71</a>
<a href="#n72" name="n72">72</a>
<a href="#n73" name="n73">73</a>
<a href="#n74" name="n74">74</a>
<a href="#n75" name="n75">75</a>
</pre></td>
  <td class="code"><pre>
<span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="class">X</span>&gt;
    <span class="keyword">struct</span> simd_vector_traits;

<span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="class">X</span>&gt;
    <span class="keyword">class</span> <span class="class">simd_vector</span>
    {
    <span class="directive">public</span>:

        <span class="keyword">typedef</span> <span class="keyword">typename</span> simd_vector_traits&lt;X&gt;::value_type value_type;

        <span class="comment">// downcast operators so we can call methods in the inheriting classes</span>
        <span class="directive">inline</span> X&amp; <span class="directive">operator</span>()() { <span class="keyword">return</span> *<span class="keyword">static_cast</span>&lt;X*&gt;(<span class="local-variable">this</span>); }
        <span class="directive">inline</span> <span class="directive">const</span> X&amp; <span class="directive">operator</span>()() <span class="directive">const</span> { <span class="keyword">return</span> *<span class="keyword">static_cast</span>&lt;<span class="directive">const</span> X*&gt;(<span class="local-variable">this</span>); }

        <span class="comment">// Additional assignment operators</span>
        <span class="directive">inline</span> X&amp; <span class="directive">operator</span>+=(<span class="directive">const</span> X&amp; rhs)
        {
            (*<span class="local-variable">this</span>)() = (*<span class="local-variable">this</span>)() + rhs;
            <span class="keyword">return</span> (*<span class="local-variable">this</span>)();
        }

        <span class="directive">inline</span> X&amp; <span class="directive">operator</span>+=(<span class="directive">const</span> value_type&amp; rhs)
        {
            (*<span class="local-variable">this</span>)() = (*<span class="local-variable">this</span>)() + X(rhs);
            <span class="keyword">return</span> (*<span class="local-variable">this</span>)();
        }

        <span class="comment">// Same for operator-=, operator*=, operator/= ...</span>
        <span class="comment">// ...</span>

        <span class="comment">// Increment operators</span>
        <span class="directive">inline</span> X <span class="directive">operator</span>++(<span class="predefined-type">int</span>)
        {
            X tmp = (*<span class="local-variable">this</span>)();
            (*<span class="local-variable">this</span>) += value_type(<span class="integer">1</span>);
            <span class="keyword">return</span> tmp;
        }

        <span class="directive">inline</span> X&amp; <span class="directive">operator</span>++()
        {
            (*<span class="local-variable">this</span>)() += value_type(<span class="integer">1</span>);
            <span class="keyword">return</span> (*<span class="local-variable">this</span>)();
        }

        <span class="comment">// Similar decrement operators</span>
        <span class="comment">// ...</span>

    <span class="directive">protected</span>:

        <span class="comment">// Ensure only inheriting classes can instantiate / copy / assign simd_vector.</span>
        <span class="comment">// Avoids incomplete copy / assignment from client code.</span>
        <span class="directive">inline</span> simd_vector() {}
        <span class="directive">inline</span> ~simd_vector() {}

        <span class="directive">inline</span> simd_vector(<span class="directive">const</span> simd_vector&amp;) {}
        <span class="directive">inline</span> simd_vector&amp; <span class="directive">operator</span>=(<span class="directive">const</span>  simd_vector&amp;) { <span class="keyword">return</span> *<span class="local-variable">this</span>; }
    };

<span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="class">X</span>&gt;
    <span class="directive">inline</span> simd_vector&lt;X&gt; <span class="directive">operator</span>+(<span class="directive">const</span> simd_vector&lt;X&gt;&amp; lhs,
                                    <span class="directive">const</span> <span class="keyword">typename</span> simd_vector_traits&lt;X&gt;::type&amp; rhs)
    {
        <span class="keyword">return</span> lhs() + X(rhs);
    }

<span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="class">X</span>&gt;
    <span class="directive">inline</span> simd_vector&lt;X&gt; <span class="directive">operator</span>+(<span class="directive">const</span> <span class="keyword">typename</span> simd_vector_traits&lt;X&gt;::type&amp; lhs,
                                    <span class="directive">const</span> simd_vector&lt;X&gt;&amp; rhs)
    {
        <span class="keyword">return</span> X(lhs) + rhs();
    }

<span class="comment">// Same for operator-, operator*, operator/</span>
<span class="comment">// ...</span>
</pre></td>
</tr></table>
 </figure></notextile></div>

<p>Now, all vector4f needs to do is to inherit from simd_vector and implement the traditional operator+, and
it will get += and ++ operators overloads for free (and the same for other arithmetic operators):</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>simd_sse.hpp </span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
<a href="#n7" name="n7">7</a>
<a href="#n8" name="n8">8</a>
<a href="#n9" name="n9">9</a>
<strong><a href="#n10" name="n10">10</a></strong>
<a href="#n11" name="n11">11</a>
<a href="#n12" name="n12">12</a>
<a href="#n13" name="n13">13</a>
<a href="#n14" name="n14">14</a>
<a href="#n15" name="n15">15</a>
<a href="#n16" name="n16">16</a>
<a href="#n17" name="n17">17</a>
<a href="#n18" name="n18">18</a>
<a href="#n19" name="n19">19</a>
<strong><a href="#n20" name="n20">20</a></strong>
<a href="#n21" name="n21">21</a>
<a href="#n22" name="n22">22</a>
<a href="#n23" name="n23">23</a>
<a href="#n24" name="n24">24</a>
<a href="#n25" name="n25">25</a>
<a href="#n26" name="n26">26</a>
<a href="#n27" name="n27">27</a>
<a href="#n28" name="n28">28</a>
<a href="#n29" name="n29">29</a>
<strong><a href="#n30" name="n30">30</a></strong>
<a href="#n31" name="n31">31</a>
<a href="#n32" name="n32">32</a>
<a href="#n33" name="n33">33</a>
<a href="#n34" name="n34">34</a>
<a href="#n35" name="n35">35</a>
<a href="#n36" name="n36">36</a>
<a href="#n37" name="n37">37</a>
<a href="#n38" name="n38">38</a>
<a href="#n39" name="n39">39</a>
<strong><a href="#n40" name="n40">40</a></strong>
<a href="#n41" name="n41">41</a>
<a href="#n42" name="n42">42</a>
<a href="#n43" name="n43">43</a>
<a href="#n44" name="n44">44</a>
<a href="#n45" name="n45">45</a>
<a href="#n46" name="n46">46</a>
<a href="#n47" name="n47">47</a>
<a href="#n48" name="n48">48</a>
<a href="#n49" name="n49">49</a>
<strong><a href="#n50" name="n50">50</a></strong>
<a href="#n51" name="n51">51</a>
</pre></td>
  <td class="code"><pre>
<span class="keyword">class</span> <span class="class">vector4f</span> : <span class="directive">public</span> simd_vector&lt;vector4f&gt;
{
<span class="directive">public</span>:

    <span class="directive">inline</span> vector4f() {}
    <span class="directive">inline</span> vector4f(<span class="predefined-type">float</span> f) : m_value(_mm_set1_ps(f)) {}
    <span class="directive">inline</span> vector4f(<span class="predefined-type">float</span> f0, <span class="predefined-type">float</span> f1, <span class="predefined-type">float</span> f2, <span class="predefined-type">float</span> f3) : m_value(_mm_setr_ps(f0,f1,f2,f3)) {}
    <span class="directive">inline</span> vector4f(<span class="directive">const</span> __m128&amp; rhs) : m_value(rhs) {}

    <span class="directive">inline</span> vector4f&amp; <span class="directive">operator</span>=(<span class="directive">const</span> __m128&amp; rhs)
    {
        m_value = rhs;
        <span class="keyword">return</span> *<span class="local-variable">this</span>;
    }

    <span class="directive">inline</span> <span class="directive">operator</span> __m128() <span class="directive">const</span> { <span class="keyword">return</span> m_value; }

    <span class="comment">// No more operator+= since it is implemented in the base class</span>

<span class="directive">private</span>:

    __m128 m_value;
};

<span class="comment">// Based on this operator implementation, simd_vector&lt;vector4f&gt; will generate</span>
<span class="comment">// the following methods and overloads:</span>
<span class="comment">// vector4f&amp; operator+=(const vector4f&amp;)</span>
<span class="comment">// vector4f operator++(int)</span>
<span class="comment">// vector4f&amp; operator++()</span>
<span class="comment">// vector4f operator+(const vector4f&amp;, ocnst float&amp;)</span>
<span class="comment">// vector4f operator+(const float&amp;, const vector4f&amp;)</span>
<span class="directive">inline</span> vector4f <span class="directive">operator</span>+(<span class="directive">const</span> vector4f&amp; lhs, <span class="directive">const</span> vector4f&amp; rhs)
{
    <span class="keyword">return</span> _mm_add_ps(lhs,rhs);
}

<span class="directive">inline</span> vector4f <span class="directive">operator</span>-(<span class="directive">const</span> vector4f&amp; lhs, <span class="directive">const</span> vector4f&amp; rhs)
{
    <span class="keyword">return</span> _mm_sub_ps(lhs,rhs);
}

<span class="directive">inline</span> vector4f <span class="directive">operator</span>*(<span class="directive">const</span> vector4f&amp; lhs, <span class="directive">const</span> vector4f&amp; rhs)
{
    <span class="keyword">return</span> _mm_mul_ps(lhs,rhs);
}

<span class="directive">inline</span> vector4f <span class="directive">operator</span>/(<span class="directive">const</span> vetcor4f&amp; lhs, <span class="directive">const</span> vector4f&amp; rhs)
{
    <span class="keyword">return</span> _mm_div_ps(lhs,rhs);
}
</pre></td>
</tr></table>
 </figure></notextile></div>

<p>Looks good, doesn’t it ? Every time we want to implement a new wrapper, we only have to code 4 operators and
make our class inherit from simd_vector, and all overloads will be generated for free!</p>

<p>Just one remark before we continue with comparison operators; if you have noticed, the base class simd_vector
defines a type named value_type, depending on the nature of the inheriting class (float for vector4f, double
for vector2d, …). However, this type is not defined by the inheriting class, but by a traits class instead.
This is a constraint of the CRTP pattern: you can access the inheriting class as long the compiler doesn’t
instantiate the code; if you call a method defined in the inheriting class, the compiler will assume it exists
until it has to instantiate the code. But type resolution is different and you have to define it out of the
inheriting class. This is one reason for the existence of the simd_vector_traits class. Other reasons will be
discussed in a later section. Note the class containing the type definition doesn’t have to be fully defined
at this point: a simple forward declaration is sufficient.</p>

<p><strong>EDIT 20/11/2014:</strong> it seems the CRTP layer introduces a slight overhead (at least with GCC), see this
<a href="http://jmabille.github.io/blog/2014/11/20/performance-considerations-about-simd-wrappers/">article</a> for more
details and an alternative solution.</p>

<h3 id="comparison-operators">2.5 Comparison operators</h3>

<p>Since ordinary comparison operators return boolean value, we need to implement SIMD wrappers for booleans. The
number of boolean elements of the wrappers will be directly related to the number of floating values wrapped
by our arithmetic wrappers.</p>

<p>In order not to duplicate code, we’ll use the same architecture as for arithmetic wrappers: a CRTP with
base class for common code, and inheriting classes for specific implementation. Here is the implementation
of the simd_vector_bool class, the base used to generate bitwise assignment operators and logical operators
overloads in inheriting classes:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>simd_base.hpp </span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
<a href="#n7" name="n7">7</a>
<a href="#n8" name="n8">8</a>
<a href="#n9" name="n9">9</a>
<strong><a href="#n10" name="n10">10</a></strong>
<a href="#n11" name="n11">11</a>
<a href="#n12" name="n12">12</a>
<a href="#n13" name="n13">13</a>
<a href="#n14" name="n14">14</a>
<a href="#n15" name="n15">15</a>
<a href="#n16" name="n16">16</a>
<a href="#n17" name="n17">17</a>
<a href="#n18" name="n18">18</a>
<a href="#n19" name="n19">19</a>
<strong><a href="#n20" name="n20">20</a></strong>
<a href="#n21" name="n21">21</a>
<a href="#n22" name="n22">22</a>
<a href="#n23" name="n23">23</a>
<a href="#n24" name="n24">24</a>
<a href="#n25" name="n25">25</a>
<a href="#n26" name="n26">26</a>
<a href="#n27" name="n27">27</a>
<a href="#n28" name="n28">28</a>
<a href="#n29" name="n29">29</a>
<strong><a href="#n30" name="n30">30</a></strong>
<a href="#n31" name="n31">31</a>
<a href="#n32" name="n32">32</a>
<a href="#n33" name="n33">33</a>
<a href="#n34" name="n34">34</a>
<a href="#n35" name="n35">35</a>
<a href="#n36" name="n36">36</a>
<a href="#n37" name="n37">37</a>
<a href="#n38" name="n38">38</a>
<a href="#n39" name="n39">39</a>
<strong><a href="#n40" name="n40">40</a></strong>
<a href="#n41" name="n41">41</a>
<a href="#n42" name="n42">42</a>
<a href="#n43" name="n43">43</a>
<a href="#n44" name="n44">44</a>
<a href="#n45" name="n45">45</a>
<a href="#n46" name="n46">46</a>
<a href="#n47" name="n47">47</a>
<a href="#n48" name="n48">48</a>
<a href="#n49" name="n49">49</a>
<strong><a href="#n50" name="n50">50</a></strong>
<a href="#n51" name="n51">51</a>
<a href="#n52" name="n52">52</a>
<a href="#n53" name="n53">53</a>
<a href="#n54" name="n54">54</a>
<a href="#n55" name="n55">55</a>
<a href="#n56" name="n56">56</a>
<a href="#n57" name="n57">57</a>
<a href="#n58" name="n58">58</a>
<a href="#n59" name="n59">59</a>
<strong><a href="#n60" name="n60">60</a></strong>
<a href="#n61" name="n61">61</a>
<a href="#n62" name="n62">62</a>
</pre></td>
  <td class="code"><pre>
<span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="class">X</span>&gt;
    <span class="keyword">class</span> <span class="class">simd_vector_bool</span>
    {
    <span class="directive">public</span>:

        <span class="directive">inline</span> X&amp; <span class="directive">operator</span>()() { <span class="keyword">return</span> *<span class="keyword">static_cast</span>&lt;X*&gt;(<span class="local-variable">this</span>); }
        <span class="directive">inline</span> <span class="directive">const</span> X&amp; <span class="directive">operator</span>()() <span class="directive">const</span> { <span class="keyword">return</span> *<span class="keyword">static_cast</span>&lt;<span class="directive">const</span> X*&gt;(<span class="local-variable">this</span>); }

        <span class="directive">inline</span> X&amp; <span class="directive">operator</span>&amp;=(<span class="directive">const</span> X&amp; rhs)
        {
            (*<span class="local-variable">this</span>) = (*<span class="local-variable">this</span>) &amp;&amp; rhs;
            <span class="keyword">return</span> (*<span class="local-variable">this</span>)();
        }

        <span class="directive">inline</span> X&amp; <span class="directive">operator</span>|(<span class="directive">const</span> X&amp; rhs)
        {
            (*<span class="local-variable">this</span>)() = (*<span class="local-variable">this</span>) || rhs;
            <span class="keyword">return</span> (*<span class="local-variable">this</span>)();
        }

        <span class="directive">inline</span> X&amp; <span class="directive">operator</span>^=(<span class="directive">const</span> X&amp; rhs)
        {
            (*<span class="local-variable">this</span>)() = (*<span class="local-variable">this</span>)() ^ rhs;
            <span class="keyword">return</span> (*<span class="local-variable">this</span>)();
        }

    <span class="directive">protected</span>:

        <span class="directive">inline</span> simd_vector_bool() {}
        <span class="directive">inline</span> ~simd_vector_bool() {}

        <span class="directive">inline</span> simd_vector_bool(<span class="directive">const</span> simd_vector_bool&amp;) {}
        <span class="directive">inline</span> simd_vector_bool&amp; <span class="directive">operator</span>=(<span class="directive">const</span> simd_vector_bool&amp;) { <span class="keyword">return</span> *<span class="local-variable">this</span>; }
    };

<span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="class">X</span>&gt;
    <span class="directive">inline</span> X <span class="directive">operator</span>&amp;&amp;(<span class="directive">const</span> simd_vector_bool&lt;X&gt;&amp; lhs, <span class="directive">const</span> simd_vector_bool&lt;X&gt;&amp; rhs)
    {
        <span class="keyword">return</span> lhs() &amp; rhs();
    }

<span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="class">X</span>&gt;
    <span class="directive">inline</span> X <span class="directive">operator</span>&amp;&amp;(<span class="directive">const</span> simd_vector_bool&lt;X&gt;&amp; lhs, <span class="predefined-type">bool</span> rhs)
    {
        <span class="keyword">return</span> lhs() &amp; rhs;
    }

<span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="class">X</span>&gt;
    <span class="directive">inline</span> X <span class="directive">operator</span>||(<span class="predefined-type">bool</span> lhs, <span class="directive">const</span> simd_vector_bool&lt;X&gt;&amp; rhs)
    {
        <span class="keyword">return</span> lhs &amp; rhs();
    }

<span class="comment">// Similar for operator|| overloads</span>
<span class="comment">// ...</span>

<span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="class">X</span>&gt;
    <span class="directive">inline</span> X <span class="directive">operator</span>!(<span class="directive">const</span> simd_vector_bool&lt;X&gt;&amp; rhs)
    {
        <span class="keyword">return</span> rhs() == <span class="integer">0</span>;
    }
</pre></td>
</tr></table>
 </figure></notextile></div>

<p>The inheriting class vector4fb only has to provide bitwise operators and equality/inequality operators:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>simd_sse.hpp</span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
<a href="#n7" name="n7">7</a>
<a href="#n8" name="n8">8</a>
<a href="#n9" name="n9">9</a>
<strong><a href="#n10" name="n10">10</a></strong>
<a href="#n11" name="n11">11</a>
<a href="#n12" name="n12">12</a>
<a href="#n13" name="n13">13</a>
<a href="#n14" name="n14">14</a>
<a href="#n15" name="n15">15</a>
<a href="#n16" name="n16">16</a>
<a href="#n17" name="n17">17</a>
<a href="#n18" name="n18">18</a>
<a href="#n19" name="n19">19</a>
<strong><a href="#n20" name="n20">20</a></strong>
<a href="#n21" name="n21">21</a>
<a href="#n22" name="n22">22</a>
<a href="#n23" name="n23">23</a>
<a href="#n24" name="n24">24</a>
<a href="#n25" name="n25">25</a>
<a href="#n26" name="n26">26</a>
<a href="#n27" name="n27">27</a>
<a href="#n28" name="n28">28</a>
<a href="#n29" name="n29">29</a>
<strong><a href="#n30" name="n30">30</a></strong>
<a href="#n31" name="n31">31</a>
<a href="#n32" name="n32">32</a>
<a href="#n33" name="n33">33</a>
<a href="#n34" name="n34">34</a>
<a href="#n35" name="n35">35</a>
<a href="#n36" name="n36">36</a>
<a href="#n37" name="n37">37</a>
<a href="#n38" name="n38">38</a>
<a href="#n39" name="n39">39</a>
<strong><a href="#n40" name="n40">40</a></strong>
<a href="#n41" name="n41">41</a>
<a href="#n42" name="n42">42</a>
<a href="#n43" name="n43">43</a>
<a href="#n44" name="n44">44</a>
<a href="#n45" name="n45">45</a>
<a href="#n46" name="n46">46</a>
<a href="#n47" name="n47">47</a>
<a href="#n48" name="n48">48</a>
<a href="#n49" name="n49">49</a>
<strong><a href="#n50" name="n50">50</a></strong>
<a href="#n51" name="n51">51</a>
<a href="#n52" name="n52">52</a>
<a href="#n53" name="n53">53</a>
<a href="#n54" name="n54">54</a>
</pre></td>
  <td class="code"><pre>
<span class="keyword">class</span> <span class="class">vector4fb</span> : <span class="directive">public</span> simd_vector_bool&lt;vector4fb&gt;
{
<span class="directive">public</span>:

    <span class="directive">inline</span> vector4fb() {}
    <span class="directive">inline</span> vector4fb(<span class="predefined-type">bool</span> b) : m_value(_mm_castsi128_ps(_mm_set1_epi32(-(<span class="predefined-type">int</span>)b))) {}
    <span class="directive">inline</span> vector4fb(<span class="predefined-type">bool</span> b0, <span class="predefined-type">bool</span> b1, <span class="predefined-type">bool</span> b2, <span class="predefined-type">bool</span> b3)
    : m_value(_mm_castsi128_ps(_mm_setr_epi32(-(<span class="predefined-type">int</span>)b0,-(<span class="predefined-type">int</span>)b1,-(<span class="predefined-type">int</span>)b2,-(<span class="predefined-type">int</span>)b3))) {}

    <span class="directive">inline</span> vector4fb(<span class="directive">const</span> __m128&amp; rhs) : m_value(rhs) {}

    <span class="directive">inline</span> vector4fb&amp; <span class="directive">operator</span>=(<span class="directive">const</span> __m128&amp; rhs)
    {
        m_value = rhs;
        <span class="keyword">return</span> *<span class="local-variable">this</span>;
    }

    <span class="directive">inline</span> <span class="directive">operator</span> __m128() <span class="directive">const</span> { <span class="keyword">return</span> m_value; }

<span class="directive">private</span>:

    __m128 m_value;
};

<span class="directive">inline</span> vector4fb <span class="directive">operator</span>&amp;(<span class="directive">const</span> vector4fb&amp; lhs, <span class="directive">const</span> vector4fb&amp; rhs)
{
    <span class="keyword">return</span> _mm_and_ps(lhs,rhs);
}

<span class="directive">inline</span> vector4fb <span class="directive">operator</span>|(<span class="directive">const</span> vector4fb&amp; lhs, <span class="directive">const</span> vector4fb&amp; rhs)
{
    <span class="keyword">return</span> _mm_or_ps(lhs,rhs);
}

<span class="directive">inline</span> vector4fb <span class="directive">operator</span>^(<span class="directive">const</span> vector4fb&amp; lhs, <span class="directive">const</span> vector4fb&amp; rhs)
{
    <span class="keyword">return</span> _mm_xor_ps(lhs,rhs);
}

<span class="directive">inline</span> vector4fb <span class="directive">operator</span>~(<span class="directive">const</span> vector4fb&amp; rhs)
{
    <span class="keyword">return</span> _mm_xor_ps(rhs,_mm_castsi128_ps(_mm_set1_epi32(-<span class="integer">1</span>)));
}

<span class="directive">inline</span> vector4fb <span class="directive">operator</span>==(<span class="directive">const</span> vector4fb&amp; lhs, <span class="directive">const</span> vector4fb&amp; rhs)
{
    <span class="keyword">return</span> _mm_cmeq_ps(lhs,rhs);
}

<span class="directive">inline</span> vector4fb <span class="directive">operator</span>!=(<span class="directive">const</span> vector4f&amp; lhs, <span class="directive">const</span> vector4fb&amp; rhs)
{
    <span class="keyword">return</span> _mm_cmpneq_ps(lhs,rhs);
}
</pre></td>
</tr></table>
 </figure></notextile></div>

<p>Now that we have wrappers for boolean, we can add the comparison operators to the vector4f class; again,
to avoid code duplication, some operators will be implemented in the base class and will be based on
specific operators implemented in the inheriting class. Let’s start with the vector4f comparison
operators:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>simd_sse.hpp </span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
<a href="#n7" name="n7">7</a>
<a href="#n8" name="n8">8</a>
<a href="#n9" name="n9">9</a>
<strong><a href="#n10" name="n10">10</a></strong>
<a href="#n11" name="n11">11</a>
<a href="#n12" name="n12">12</a>
<a href="#n13" name="n13">13</a>
<a href="#n14" name="n14">14</a>
<a href="#n15" name="n15">15</a>
<a href="#n16" name="n16">16</a>
<a href="#n17" name="n17">17</a>
<a href="#n18" name="n18">18</a>
<a href="#n19" name="n19">19</a>
<strong><a href="#n20" name="n20">20</a></strong>
<a href="#n21" name="n21">21</a>
<a href="#n22" name="n22">22</a>
</pre></td>
  <td class="code"><pre>
<span class="comment">// Definition of vector4f and arithmetic overloads</span>
<span class="comment">// ...</span>
<span class="directive">inline</span> vector4fb <span class="directive">operator</span>==(<span class="directive">const</span> vector4f&amp; lhs, <span class="directive">const</span> vector4f&amp; rhs)
{
    <span class="keyword">return</span> _mm_cmpeq_ps(lhs,rhs);
}

<span class="directive">inline</span> vector4fb <span class="directive">operator</span>!=(<span class="directive">const</span> vector4f&amp; lhs, <span class="directive">const</span> vector4f&amp; rhs)
{
    <span class="keyword">return</span> _mm_cmpneq_ps(lhs,rhs);
}

<span class="directive">inline</span> vector4fb <span class="directive">operator</span>&lt;(<span class="directive">const</span> vector4f&amp; lhs, <span class="directive">const</span> vector4f&amp; rhs)
{
    <span class="keyword">return</span> _mm_cmplt_ps(lhs,rhs);
}

<span class="directive">inline</span> vector4fb <span class="directive">operator</span>&lt;=(<span class="directive">const</span> vector4f&amp; lhs, <span class="directive">const</span> vector4f&amp; rhs)
{
    <span class="keyword">return</span> _mm_cmple_ps(lhs,rhs);
}
</pre></td>
</tr></table>
 </figure></notextile></div>

<p>Before we implement operator&gt; and operator&gt;= for the base class, we have to focus on their return
type. If these operators were implemented for vector4f, we would have return vector4fb; but since
they are implemented for the base class, they need to return the boolean wrapper related to the
arithmetic wrapper, i.e the inheriting class. What we need here is to provide a mapping between
arithmetic wrapper type and boolean wrapper type somewhere. Remember the simd_vector_traits structure
we declared to define our value_type ? It would be the perfect place for defining that mapping:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>simd_sse.hpp</span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
<a href="#n7" name="n7">7</a>
<a href="#n8" name="n8">8</a>
<a href="#n9" name="n9">9</a>
<strong><a href="#n10" name="n10">10</a></strong>
<a href="#n11" name="n11">11</a>
<a href="#n12" name="n12">12</a>
<a href="#n13" name="n13">13</a>
<a href="#n14" name="n14">14</a>
<a href="#n15" name="n15">15</a>
<a href="#n16" name="n16">16</a>
</pre></td>
  <td class="code"><pre>
<span class="comment">// simd_vector_traits&lt;vector4f&gt; must be defined before vector4f so simd_vector can compile</span>
<span class="comment">// (remember we use simd_vector_traits&lt;X&gt;::value_type in the definition of simd_vector).</span>
<span class="keyword">class</span> <span class="class">vector4f</span>;

<span class="comment">// Full specialization of the template simd_vector_traits declared in simd_base.hpp</span>
<span class="keyword">template</span> &lt;&gt;
    <span class="keyword">struct</span> simd_vector_traits&lt;vector4f&gt;
    {
        <span class="keyword">typedef</span> <span class="predefined-type">float</span> value_type;
        <span class="keyword">typedef</span> simd_vector4fb vector_bool;
    };

<span class="keyword">class</span> <span class="class">vector4f</span>
{
    <span class="comment">// ...</span>
</pre></td>
</tr></table>
 </figure></notextile></div>

<p>A last remark before we add the last comparison operators: since the template simd_vector_traits
will never be defined but fully specialized instead, there is no risk we forget to define it when
we add a new wrapper, we’ll have a compilation error.</p>

<p>Finally, we can add the missing operators for the base class:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>simd_base.hpp </span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
<a href="#n7" name="n7">7</a>
<a href="#n8" name="n8">8</a>
<a href="#n9" name="n9">9</a>
<strong><a href="#n10" name="n10">10</a></strong>
<a href="#n11" name="n11">11</a>
<a href="#n12" name="n12">12</a>
<a href="#n13" name="n13">13</a>
<a href="#n14" name="n14">14</a>
<a href="#n15" name="n15">15</a>
<a href="#n16" name="n16">16</a>
<a href="#n17" name="n17">17</a>
</pre></td>
  <td class="code"><pre>
<span class="comment">// Declaration of simd_vector and operators</span>
<span class="comment">//...</span>

<span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="class">X</span>&gt;
    <span class="directive">inline</span> <span class="keyword">typename</span> simd_vector_traits&lt;X&gt;::vector_bool
    <span class="directive">operator</span>&gt;(<span class="directive">const</span> simd_vector&lt;X&gt;&amp; lhs, <span class="directive">const</span> simd_vector&lt;X&gt;&amp; rhs)
    {
        <span class="keyword">return</span> rhs() &lt;= lhs();
    }

<span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="class">X</span>&gt;
    <span class="directive">inline</span> <span class="keyword">typename</span> simd_vector_traits&lt;X&gt;::vector_bool
    <span class="directive">operator</span>&gt;=(<span class="directive">const</span> simd_vector&lt;X&gt;&amp; lhs, <span class="directive">const</span> simd_vector&lt;X&gt;&amp; rhs)
    {
        <span class="keyword">return</span> rhs() &lt; lhs();
    }
</pre></td>
</tr></table>
 </figure></notextile></div>

<h3 id="logical-operators">2.6 Logical operators</h3>

<p>Since float provides logical operators, our wrapper should do so. The implementation is the same
as for the simd_vector_bool class, that is logical assignment operator in the simd_vector base class,
and operator overloads for the inheriting classes. The implementation of operator|, operator&amp;, operator^
and operator~ is the same as the one for vector4fb, so I don’t repeat it here.</p>

<h3 id="next-step">2.7 Next step</h3>

<p>Next step is to implement wrapper for 2 double, then wrapper for 8 float and 4 double if you want to support
AVX. You can also implement wrappers for int if you aim to do integre computation. The implementation is
similar to what has been done in this section.</p>

<p>Now we have nice wrappers, we’ll see in the next section how to plug them into existing code.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Writing C++ Wrappers for SIMD Intrinsics (2)]]></title>
    <link href="http://jmabille.github.io/blog/2014/10/10/writing-c-plus-plus-wrappers-for-simd-intrinsics-2/"/>
    <updated>2014-10-10T00:54:37+02:00</updated>
    <id>http://jmabille.github.io/blog/2014/10/10/writing-c-plus-plus-wrappers-for-simd-intrinsics-2</id>
    <content type="html"><![CDATA[<h2 id="a-namesection1a1-sseavx-intrinsics"><a name="section_1"></a>1. SSE/AVX intrinsics</h2>

<p>Before we start writing any code, we need to take a look at the instrinsics provided with the compiler. Henceforth, I
assume we use an Intel processor, recent enough to provide SSE 4 and AVX instruction sets; the compiler can be gcc or
MSVC, the instrinsics they provide are almost the same.</p>

<p>If you already know about SSE / AVX intrinsics you may skip this section.
<!-- more --></p>

<h3 id="registers">1.1 Registers</h3>

<p>SSE uses eight 128 bits registers, from xmm0 to xmm7; Intel and AMD 64 bits extensions adds eight more registers, from
xmm8 to xmm15; thus SSE intrinsics can perform on 4 packed float, 2 packed double, 4 32-bits integers, etc …</p>

<p>With AVX, the width of the SIMD registers is increased from 128 to 256 bits; the register are renamed from xmm0-xmm7
to ymm0-ymm7 (and from xmm8-xmm15 to ymm8 to ymm15); however legacy sse instructions still can be used, and xmm
registers can still be addressed since they’re the lower part of ymm registers.</p>

<p>AVX512 will increase the width of the SIMD registers from 256 to 512 bits.</p>

<h3 id="files-to-include">1.2 Files to include</h3>

<p>Intrinsic functions are made available in different header files, based on the version of the SIMD instruction set they
belong to:</p>

<ul>
  <li>&lt;xmmintrin.h&gt; : SSE, operations on 4 single precision floating point numbers (float).</li>
  <li>&lt;emmintrin.h&gt; : SSE 2, operations on integers and on 2 double precision floating point numbers (double).</li>
  <li>&lt;pmmintrin.h&gt; : SSE 3, horizontal operations on SIMD registers.</li>
  <li>&lt;tmmintrin.h&gt; : SSSE 3, additional instructions.</li>
  <li>&lt;smmintrin.h&gt; : SSE 4.1, dot product and many operations on integers</li>
  <li>&lt;nmmintrin.h&gt; : SSE 4.2, additional instructions.</li>
  <li>&lt;immintrin.h&gt; : AVX, operations on integers, 8 float or 4 double.</li>
</ul>

<p>Each of these files includes the previous one, so you only have to include the one matching the highest version of the SIMD
instruction set available in your processor. Later we will see how to detect at compile time which version on SIMD instruction
set is available and thus which file to include. For now, just assume we’re able to include the right file each time we need it.</p>

<h3 id="naming-rules">1.3 Naming rules</h3>

<p>Now if you take a look at these files, you will notice provided data and functions follow some naming rules :</p>

<ul>
  <li>data vectors are named <strong>__mXXX(T)</strong>, where :
    <ul>
      <li>XXX is the number of bits of the vector (128 for SSE, 256 for AVX)</li>
      <li>is T a character for the type of the data; T is omitted for float, i fot integers and d for double; thus __m128d is the
  data vector to use when performing SSE instructions on double.</li>
    </ul>
  </li>
  <li>intrinsic functions operating on floating point numbers are usually named <strong>_mm(XXX)_NAME_PT</strong>, where :
    <ul>
      <li>XXX is the number of bits of the SIMD registers; it is omitted for 128 bits registers</li>
      <li>NAME is the short name of the function (add, sub, cmp, …)</li>
      <li>P indicates whether the functions operates on a packed data vector (p) or on a scalar only (s)</li>
      <li>T indicates the type of the floating point numbers : s for single precision, d for double precision</li>
    </ul>
  </li>
  <li>intrinsic functions operating on integers are usually named <strong>_mm(XXX)_NAME_EPSYY</strong>, where :
    <ul>
      <li>XXX is the number of bits of the SIMD registers; it is omitted for 128 bits registers</li>
      <li>NAME is the short name of the function (add, sub, cmp)</li>
      <li>S indicates whether the integers are signed (i) or unsigned (u)</li>
      <li>YY is the number of bits of the integer</li>
    </ul>
  </li>
</ul>

<h3 id="intrinsics-categories">1.4 Intrinsics categories</h3>

<p>Intrinsics encompass a wide set of features; we can distinguish the following categories (not exhausive) :</p>

<ul>
  <li>Arithmetic : _mm_add_xx, _mm_sub_xx, _mm_mul_xx, _mm_div_xx, …</li>
  <li>Logical : _mm_and_xx, _mm_or_xx, _mm_xor_xx, …</li>
  <li>Comparison : _mm_cmpeq_xx, _mm_cmpneq_xx, _mm_cmplt_xx, …</li>
  <li>Conversion : _mm_cvtepixx, …</li>
  <li>Memory move : _mm_load_xx, _mm_store_xx, …</li>
  <li>Setting : _mm_set_xx, _mm_setzero_xx, …</li>
</ul>

<p>I will not provide wrappers for all intrinsics,  and some of them will be used only to build higher level functions in the wrappers.</p>

<h3 id="sample-code">1.5 Sample code</h3>

<p>Now you know a little more about SSE and AVX intrinsics, you may reconsider the need for wrapping them; indeed, if you don’t need
to handle other instructions set, you could think of using SSE/AVX intrinsics directly. I hope this sample code will make you
change your mind :</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>SSE_sample.cpp </span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
<a href="#n7" name="n7">7</a>
<a href="#n8" name="n8">8</a>
</pre></td>
  <td class="code"><pre>
<span class="comment">// computes e = a*b + c*d using SSE where a, b, c, d and e are vector of floats</span>
<span class="keyword">for</span>(size_t i = <span class="integer">0</span>; i &lt; e.size(); i += <span class="integer">4</span>)
{
    __m128 val = _mm_add_ps(_mm_mul_ps(_mm_load_ps(&amp;a[i]),_mm_load_ps(&amp;b[i])),
                            _mm_mul_ps(_mm_load_ps(&amp;c[i]),_mm_load_ps(&amp;d[i])));
    _mm_store_ps(&amp;e[i],val);
}
</pre></td>
</tr></table>
 </figure></notextile></div>

<p>Quite hard to read, right ? And this is just for two multiplications and one addition; imagine using intrinsics in a huge amount of code,
and you will get code really hard to understand and to maintain. What we need is a way to use __m128 with traditional arithmetic
operators, as we do with float :</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>wrapped_sample.cpp </span></figcaption>
 <table class="CodeRay"><tr>
  <td class="line-numbers"><pre><a href="#n1" name="n1">1</a>
<a href="#n2" name="n2">2</a>
<a href="#n3" name="n3">3</a>
<a href="#n4" name="n4">4</a>
<a href="#n5" name="n5">5</a>
<a href="#n6" name="n6">6</a>
<a href="#n7" name="n7">7</a>
</pre></td>
  <td class="code"><pre>
<span class="comment">// computes e = a*b + c*d using SSE where a, b, c, d and e are vector of floats</span>
<span class="keyword">for</span>(size_t i = <span class="integer">0</span>; i &lt; e.size(); i += <span class="integer">4</span>)
{
    __m128 val = load(&amp;a[i]) * load(&amp;b[i]) + load(&amp;c[i]) * load(&amp;d[i]);
    store(&amp;e[i],val);
}
</pre></td>
</tr></table>
 </figure></notextile></div>

<p>That’s the aim of the wrappers we start to write in the next section.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Writing C++ Wrappers for SIMD Intrinsics (1)]]></title>
    <link href="http://jmabille.github.io/blog/2014/10/09/writing-c-plus-plus-wrappers-for-simd-intrinsics-1/"/>
    <updated>2014-10-09T09:10:38+02:00</updated>
    <id>http://jmabille.github.io/blog/2014/10/09/writing-c-plus-plus-wrappers-for-simd-intrinsics-1</id>
    <content type="html"><![CDATA[<h2 id="a-nameintroductionaintroduction"><a name="introduction"></a>Introduction</h2>

<p>SIMD (and more generally vectorization) is a longstanding topic and a lot has been written about it. But
when I had to use it in my own applications, it appeared that most of the articles were theoretical,
explaining the principles vectorization lacking practical examples; some of them, however, linked to
libraries using vectorization, but extending these libraries for my personal needs was difficult, if not
painfull. For this reason, I decided to implement my own library. This series of articles if the result
of my work on the matter. I share it there in case someone faces the same problem.</p>

<!-- more -->

<p>SIMD stands for Single Instruction, Mutiple Data, a class of parallel computers which can perform
the same operation on multiple data points simultaneously. Let’s consider a summation we want to perform
on two sets of four floating point numbers. The difference between scalar and SIMD operations is illustrated
below:</p>

<p><img src="http://jmabille.github.io/images/simd_scalar.png" alt="simd_scalar" /></p>

<p>Using scalar operation, four add instructions must be executed one after other to obtain the sums, whereas
SIMD uses a single instruction to achieve the same result. Thus SIMD operations achieve higher efficiency than
scalar operations.</p>

<p>SIMD instructions were first used in the early 1970s, but only became available in consumer-grade chips in the
90s to allow real-time video processing and advanced computer graphics for video games. Each processor manufacturer
has implemented its own SIMD instruction set:</p>

<ul>
  <li>MMX / SSE / AVX (Intel processors)</li>
  <li>3DNow! (AMD processors)</li>
  <li>Altivec (Motorola processors)</li>
  <li>MDMX (MIPS processors)</li>
</ul>

<p>Many of these instruction sets still coexist nowadays, and you have to deal with all of them if you want to write portable
software. This is a first argument for writing wrappers: capture the abstraction of SIMD operations with nice interfaces,
and forget about the implementation you rely on.</p>

<p>Although you can write assembly code to use the SIMD instructions, compilers usually provide built-in functions so you
can use SIMD instructions in C without writing a single line of assembly code. These functions (and more generally functions
whose implementation is handled specially by the compiler) are called intrinsic functions, often shortened to intrinsics.
Of course the SIMD intrinsics depend on the underlying architecture, and may differ from one compiler to other even for a
same SIMD instruction set. Fortunately, compilers tend to standardize intrinsics prototype for a given SIMD instruction set,
and we only have to handle the differences between the various SIMD instruction sets.</p>

<p>In this series of article, the focus will be on wrapping Intel’s SIMD instruction set, although the wrappers will be generic
enough so that plugging other instruction sets is easy.</p>

<p>Since SIMD instructions are longstanding, you might wonder if writing your own wrapper is relevant; maybe you could reuse
an existing library wrapping these intrinsics. Well, it depends on your needs.</p>

<p><a href="http://www.agner.org/optimize/#vectorclass">Agner Fog</a> has written some very usefull classes that handle Intel SIMD
instruction set (different versions of SSE and AVX), but he doesn’t make heavy use of metaprogramming in his
implementation. Hence adding a new wrapper (for a new instruction set, a new version of an existing one or even for
your own numerical types)  requires to type a lot of code that could otherwise have been factorized. Moreover, some essential
tools are missing, such as an aligned memory allocator (we will see why you need such a tool later). However his library is
a good starting point.</p>

<p>Another library you might want to consider is the <a href="https://github.com/MetaScale/nt2">Numerical Template Toolbox</a>.
Although it has a very comprehensive set of mathematical functions, its major drawback is that it really slows the
compilation. Moreover its development and documentation aren’t finished yet, and it might be difficult to extend it.</p>

<p>And last but not least, writing your own wrapper will make you confront issues specific to SIMD instructions
and make you understand how it works; thus you will be able to use SIMD intrinsics in a really efficient way, regardless
of the implementation you choose (your own wrappers or an existing library).</p>

]]></content>
  </entry>
  
</feed>
